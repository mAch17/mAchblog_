{
  
    
        "post0": {
            "title": "Thoughts On Ai Specific Hardware",
            "content": "I wrote this as an explanation of how AI specific hardware (in fact also how any hardware) works in combination with the Software and how it might effect AI startups in short term and long term. . By AI specific hardware, I mean new chips being developed just for running AI algorithms in general. However, in this discussion I will speak about hardware being developed to run Deep Learning algorithms in particular. The reason is : A. Deep Learning algorithms require way more compute than any other AI algorithms and thus AI specific hardware is more desired for them. We already need special Hardware like GPUs to run them for all practical purposes. B. Other Machine Learning algorithms (and even normal data analytics) have started migrating to GPU only recently and not too much work seems to have been done to make specialized hardware for them. . When I removed details specific to my startup (I am one of co-founders of ParallelDots) from this answer, I found this had become a long essay! Before you read, please understand that this is an opinion/prediction document. I am not an expert at hardware and electronics by any means and there may be mistakes. I am just trying to make sense out of a related but unknown field to my field of work (My work is mostly in the field of Machine Learning and Software). . Introduction . One subtrend in the recent AI interest post 2012 is that of AI specific hardware. We all know that it takes lot of (costly) hardware to train Deep Neural Network. Every Nvidia-GPU worth training AI on is a costly machine and the recent mega models trained on large repositories data are trained on an insane amount of compute. An excerpt from the latest BYOL self supervised learning paper by DeepMind: . Some reaction on size of the latest OpenAI GPT3 model: . . . So, I hope everyone agrees that research on Deep Learning specific hardware is not a bad investment. It can make deploying AI cheaper, reduce CO2 emissions and many do many other good things. More efficient Hardware will give better results. In fact, even the post AlexNet Deep Learning revolution happened because GPUs were made available. Convnets/LSTMs have been around since late 1980s- early 1990s, nothing substancial came out before the hardware was available. . Let’s talk now about Computer hardware and AI specific hardware in particular: . About Different Hardware Platforms . Microprocessors/chips in our computers: . To understand these, we will have to understand how does a program written by a person work ? A programming language compiler converts a program written by a human into a machine readable format. What is a machine readable format ? While most people understand that this is zeros and ones (which is true), in reality, the zeros and ones are actually a low level program that can run on hardware directly. Basically low level instructions are fabricated into the hardware directly. These low level instructions are for example, mathematical operations like Sum, Product, And, Or, Not etc. (General term for this set of logic fabricated into hardware is called instruction set). Now when we are building hardware for a general laptop say, we need to keep the instruction set “Turing Complete”. Turing Complete is a set of instructions in which any program can be represented. This enables the laptop’s chips to be generic and run any possible logic. However, a chip having a generic instruction set is not the most efficient chip for any possible problem. The generic instruction set is build in a way it is good enough for most problems, but specialized hardware is often added for tasks which require more computation. For example, Real Number operations (1.0+1.0) are relatively slow on a generic CPU as compared to Whole Number operations (1 + 1) as they require more computation. A hardware which just runs Floating Point computations fast is present in most Computers by default to optimize (due to the prevalence of floating point ops). In fact, VLSI research has progressed enough to make sure the specialized that floating point hardware is small enough to fit on CPU itself. . GPUs: . GP-GPUs ( General Purpose – Graphic Processing Units), commonly known as GPUs are specialized hardware to run a set of mathematical operations very efficiently. When the feature rich GPUs came out in late-2000s, they were like a super computer could be installed right on your laptop. The compute GPUs provide actually enabled two big trends : Blockchain and AI. Most new Supercomputers we have now days are clusters of GPU. This is in stark contrast of just one decade back, when they were all special purpose hardware. GPUs are still quite general purpose, in the sense they cannot run all programs in parallel, but can run many mathematical operations in parallel. Due to this, they are costly. A simple trend can be understood that most bitcoin mining (which was one of the biggest usecases of GPUs earlier), has migrated to other specialized hardware as new hashes are rarer to find and incrementally more compute is needed as the currency is used. The special purpose hardware has less generic but more optimized functionality for bitcoin mining bringing the compute cost down. . In AI, however, the compute cost is not climbing as much, so well GPUs still continue to be used. Also much more compute is needed at the time of training than deployment. However, there is almost always a debate about deployment as there is significant server costs to be incurred when algorithms are run at scale. While for some applications, the cost might be justified, it might be not for others. So, what do we do to get better bang-for-buck ? Same, less generic and more optimized hardware. . AI specific hardware: . There are two directions of work for AI specific chips : . The bitcoin way : . That is make more specific hardware than only target the GPU instruction set components aiding Neural Network training (GPUs have a broader instruction set that runs Graphics operations along with other compute). This is how most Bitcoin specific hardware was developed and this has been quite successful there(Technique is called ASICS – Application Specific ICs). In AI technology too, many people have tried this model successfully. . Google for example is already offering its specialized AI hardware on cloud : https://en.wikipedia.org/wiki/Tensor_processing_unit . We also have attempts by Alibaba (on its AWS competitor) : https://techxplore.com/news/2019-09-alibaba-crowns-cloud-powerful-ai.html and Intel : https://techxplore.com/news/2018-11-usb-neural-debut-event.html . These chips are very efficient for Vector Operations, Matrix Multiplications and graph structured data handling, two most common compute routines needed for Neural Network. AliBaba, for example claims its chip is 15 times more powerful than Nvidia’s T4 deployment GPUs and way more powerful than P4 when used for inference of product images. While the Alibaba device is offered on its cloud, just like Google’s device, the Intel device is a &lt;$100 USB device to deploy AI algorithms on laptops or Raspberry Pies. . . . Both Google and Nvidia have also launched consumer AI deployment hardware like the Intel chip in $100 price range. https://spectrum.ieee.org/geek-life/hands-on/the-coral-dev-board-takes-googles-ai-to-the-edge and https://spectrum.ieee.org/geek-life/hands-on/quickly-embed-ai-into-your-projects-with-nvidias-jetson-nano respectively. . More research is being done to try and incorporate Spiking Neural Network operations on ASICS rather than normal Neural Network Operations. Spiking Neural Networks emulate the brain more closely than the Artificial Neural Networks we use more commonly. https://techxplore.com/news/2018-12-hardware-software-co-design-approach-neural-networks.html . . There are also efforts to make extremely low power requirement hardware for small or miniature robots to perform Reinforcement learning on edge and learn online as they work in field. One method to do so is to merge traditional Digital and Analog devices for making ASICS. https://techxplore.com/news/2019-03-ultra-low-power-chips-small-robots.html . . ,.,.,.,.,.,.,.,.,. | The Brain Inspired Way . This is a different approach to build AI specific hardware. Also this is more “cool” in the way that it wants to change the hardware implementation quite fundamentally. While Matrix Multiplications and Vector Operations are layer by layer way to abstract a Neural Network operation, One can abstract it out in another way, at neuron level. Infact the Matrix Multiplication and non-linearity combination we use for every layer of Neural Network can be thought of as less efficient way of implementing artificial neurons in one layer of neural network. If we can represent the artificial neuron on the hardware, we don’t need to even do these costly matrix multiplications (and so hardware costs should go down even more). Essentially the instruction set for running neural networks will now change from Matrix multiplications to neurons. The method is more interesting also because one is building hardware that actually tries to emulate brain Neurons (We do it in software for a very long time, it will now be available in hardware directly). The long term aim here is that we should be able to pack much much more optimized compute for AI algorithms on one chip than what we have now, increasing the training and inference accuracy manifold. | So how do these hardware designs work you ask ? Let’s do a mini survey : . One thing that you should probably think about is that these approaches are of two types, A. having programmable weights and dumb thresholding, like what our software based Neural Networks have and B. Working using smart learnable thresholding (synaptic). . Simplest way you can think of the change happening, is at the Transistor layer, where instead of traditional transistor, we use a Neuron Transistor. That is, it takes input charges and can do what a basic artificial neuron does with its input, weighted sum followed by thresholding (thresholding determines whether a Neuron fires or stays inactive for an input). https://phys.org/news/2017-06-neuron-transistor-brain.html developed a Neuron Transistor in form of a Molybdenum Disulphide flake that works like an artificial neuron. . This however models one Neuron, we have to also build a chip that can model Dense connection between Neurons so that multiple layers of a Deep Artificial Neural Network can be emulated on the chip. In human brain, the process of the dense connections is done by Synapses. These synapses threshold the signal and fire (ie pass information) for a strong signal and stay put for a weak one. https://phys.org/news/2018-01-artificial-synapse-brain-on-a-chip-hardware.html have designed this signal carrier layer (or artificial synapses) for use on a chip using a 2D Silion-Germanium material. They have even trained an MNIST classifier using the new synpases hardware. . . Another direction of research for brain inspired computing is the one using Memristors. Memristors are electronic components which can both perform computations and store data. The data is stored by programming the resistance of the memristor. If you have seen functioning of any Neural Network, you will be able to relate memristors with Neurons. Neurons both store data (that is weights) and perform computations (forward propagation/ backward propagation) on inputs and weights both. There have always been attempts to learn Neural Networks through memristor elements, as the programmable resistance component help memristors save data as a continuum (like Neural Network weights), rather than binary states like 0/1. In speech recognition/generation, Neural Networks running on memristor can run realtime with respect to Human Speech. https://phys.org/news/2017-12-memristors-power-quick-learning-neural-network.html . However, the problem with memristors is that the resistance value stored on them is not precise enough (like the float point values F16/32/64 we train/use our Neural Networks at). To counter this, one approach is basically discretize the values of these memory resistances (thus arriving at multiple states like 0,1,2….) and then use this to store floating points precisely. Afterall, as we saw earlier, even CPUs store all floating points as binary values. This helps us have precise floating points with some tradeoffs. The method is called Memory Processing Units. . Link: https://techxplore.com/news/2018-07-memory-processing-memristors-masses.html . Just like in software, it seems in hardware too, larger the number of memristor devices one can support, the better is the accuracy. However, too many Memristors would also mean too much need of energy. To solve this, researchers have built atomic level memristors which are energy effcient. Silver and Boron-Nitride topped on Graphene have been used to build such microscopic memristors that can work in parallel. These memristors help model the weighted averaging property of Neurons. . Link :: https://phys.org/news/2018-10-memristor-boosts-accuracy-efficiency-neural.html . . Another way to make molecular level memristors is to use Molybdenum Disulphide (our friend whom we have already seen previously) with Lithium. These memristors can be a way to model thresholding in Artificial Neurons. Molybdenum Disulphide behaves like a semi-conductor generally, allowing less current flow, but in presence of Lithium ions, it changes its structure starting to behave like a conductor. Thus, the amount of Lithium varying can build the thresholding of firing of Neurons, doing what synpases do in real brains. Electric field can control flow of Lithium ions, helping us program the system. . Link: https://phys.org/news/2018-12-brain-like-memristor-mimics-synapses.html . . Another cool work is doing Associative Learning on a memristor based hardware. Associative Learning for Software based Machine Learning practitioners is what Reinforcement Learning is. While most Memristor based technologies need input-output together to learn, in real world, action and reward are often not happening at the same time. A time-delayed input based Memristor Synapse was invented for this purpose. Link :: https://techxplore.com/news/2019-12-memristor-based-neural-network-notion-associative.html . https://techxplore.com/news/2019-07-programmable-memristor-aims-ai-cloud.html is a programmable memristor circuit which can be used in real world for two-layered Neural Networks. It can still work on toy problems only, but is generic to be trained across whatever domain you want. Big step indeed. . . More recent innovations include training 3D memristors for the purpose. These enable even more densely connected (deeper due to more possible paths ?) memristor Neural Networks to be run. 3D electronic devices are hard to make from what I can gather and this seems like another big achievement. The unique “local connections” based topology these inventors used not only allows them to build a 3D memristor circuit but also train Convnets, in contrast to old memristor technologies which can only use FC layers. https://techxplore.com/news/2020-05-d-memristor-based-circuit-brain-inspired.html . . In a similar attempt to put many-many memristors together to make the devices capable of inference on real world problems, researches solved the problem of diluted voltage for ion movement in case of many memristors on a chip. They did this by allowing the Silver + node with Copper and using a Silicon -ve node for ion movement voltage. This let them put 100s of thousands of memristors on a single chip. The aim is to do inference on the edge based on small devices rather than GPUs or supercomputers. . http://news.mit.edu/2020/thousands-artificial-brain-synapses-single-chip-0608 . . Short term impact on Machine Learning companies (tech/businesswise) : . Short Term changes are not really hard to guess. Cloud infrastructure bill for an AI company is comparatively higher than what it should be for a SaaS company of the same scale and revenue. The reason is that they right now use GPUs a lot. There are two types of GPUs in usage : . A. Cheaper low power GPUs to deploy AI models. On cloud generally Nvidia T4/P4 are used. This is one area where alternative AI hardware has made inroads. TPUs are pretty common alternative on cloud here and devices like Nvidia Jetson nano , Google Coral and Intel Neural Compute Stick in IoT. . B. Costlier high powered GPUs for training AI algorithms. In fact, for training many large algorithms, you need a GPU cluster. OpenAI trained its recent GPT3 model on one of world’s most powerful GPU based supercomputers. . At least on paper for both A and B, TPUs seem to be very very cost effective. While my startup has not yet started adapting models to deploy on TPUs yet (we use cheap inference GPUs on cloud for deployment and in office large GPUs for training), AI blogs praise it as a effective device for both purposes in cloud. https://medium.com/bigdatarepublic/cost-comparison-of-deep-learning-hardware-google-tpuv2-vs-nvidia-tesla-v100-3c63fe56c20f . You can assume that in short run, deployment and training of AI will get cheaper with respect to model size. This will have two effects : . 1. Low complexity models will start to be deployed for cases where they are assumed to be too costly right now. . 2. Larger and more accurate models will be trained. At least for now, it seems “Bigger is Better” is true in Neural Networks. . “One requirement for all AI specific hardware platforms is to make the cost to switch very low. The more code needs to be rewritten to adapt software to the new platforms, the bigger gains in performance they will have to show to the people to make the investment to switch.” . Long Term Effect of AI specific hardware – Rise of AutoML . [I was actually answering “Is the relationship between AI hardware and GPU like that of manual shift and automatic shift in cars ?”] . A good analogy for GPUs and AI specific hardware is IC Engine vs Electric Vehicle hardware. Its a new way of doing the same thing efficiently. For example, no changes in code need to be done to deploy a model trained on Nvidia GPUs and to make it work on Google’s AI specific hardware(TPUs). You won’t even feel the difference while working on an AI problem as an engineer, but the hardware that deploys code is more efficient and costs less. Free lunch in some ways (you do lose some flexibility of writing more generic programs with the general purpose hardware as I said earlier, but it doesn’t matter for most AI algorithms). What is happening with the AI specific hardware is the AI programs we write burn less compute/context in getting translated to hardware code to run (because of some software instructions now directly runnable on hardware without translation) and hence more compute to run the programs themselves. . However, there are other technologies, which involve “AI making AI” and are apt to the automatic-shift vs Manual Shift analogy in AI. If you want to read more about these technologies, good terms to look for are AutoML, Automated Machine Learning (both these terms used in automation of traditional machine learning) and Neural Architecture Search (specific term for Deep Learning). These techniques are not really making writing AI easier for all engineers, but are making writing all AI easier for just a few smart engineers. So just like we are automating some parts of jobs of Software Developers, BPOs, web designers, cab drivers, we are automating low skill AI tasks too. . These AutoML techniques are still AI algorithms, which instead of solving a problem directly, learn to develop a problem solver. Just like some humans can better look at an image and describe it as compared to an AI algorithm, there are Machine Learning practitioners who can beat AutoMLtechniques easily as of now (Otherwise, AutoML would win all Machine Learning competitions). There is still art in smart Human Observation and Intuition which these algorithms are far from beating. What AutoML is good at right now is finding out good enough solutions, so you don’t need an engineer for every single Data Learning problem. However, this is where cheap and efficient hardware (specially very efficient ones like Neurons on Chip hardware) can come in handy. One limiting factor of AutoML (even today) is compute. Efficient Hardware can give computers extreme power to do what computers are really good at for cheap money in the field of AutoML, that is, trial-and-error for learning what humans try to solve by wisdom and intuition. Apart from making AI technology cheaper, this is where I see the greatest potential of AI hardware, scaling up AutoML to actually start getting “superb” results from “good” results like right now. .",
            "url": "https://muktabh.xyz/2020/06/22/Thoughts-on-AI-specific-Hardware.html",
            "relUrl": "/2020/06/22/Thoughts-on-AI-specific-Hardware.html",
            "date": " • Jun 22, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Observations On Ongoing Coronavirus Pandemic",
            "content": "This is a combination of many recent Quora answers of mine related to ongoing COVID19 pandemic. . My answer to “What is herd immunity, and how can it be effective for countries like India? ” . Originally answered here: https://qr.ae/pNywoi . “Herd Immunity” is a state of a communicable disease (epidemic/pandemic) where enough people from the susceptible population have become immunity-wise resistant to the disease so as to not to spread it to more venerable people of society who have weak immunity or who cannot develop immunity (Cancer patients, little children, seniors etc.). These venerable people are typically at more risk during the outbreak. . Once this state is reached, it will end up confining the disease in small pockets of low resistance and pandemic would end as such. Reaching Herd Immunity is thus how any communicable disease will be controlled in the long run. However, how we reach herd immunity is more important than we think. There are people with crazy theories about reaching herd immunity (like injecting young healthy people with virus etc.), however, if there is one thing you should take away from this answer, it is “Herd Immunity without vaccine is a Joke for a contagious disease”. . Let’s say for the most contagious diseases out there like measles, if we don’t have a vaccine, how many people need to get infected before herd immunity is achieved. Answer is around 95% of the population. COVID19 is less contagious than measles (but more so than the flu) and hence around 70% of the people need to get infected for herd immunity to be achieved. Think of 70% of 1.3 Billion getting (around 900 million or 90 Crore people) sick if one wants to achieve herd immunity this way. Think of the number of people losing their lives if this happens (3% of 90 Crore is 3 Crore if you try to estimate by Indian numbers and assume that the curve would stay flattened not making the mortality ratio higher) . Another big assumption in the 70% population who get sick develop long term immunity. We are not sure of the fact that a person who gets cured of COVID19 is immune to the disease in the long term, heck the pandemic just started spreading few months back. “Absence of Evidence is not Evidence of Absence”. There were some news (not supported too scientifically) that some cured people in South Korea contracted COVID19 again. Other species of Coronavirus that cause common cold dont seem to make humans develop any long term immunity. Everyone contracts cold once or twice a year, every year. If such is the case, you cannot achieve herd immunity ever despite infecting everyone ! . We also don’t have any records of long term effects the COVID19 infections are causing. It seems there are none as of now, but what if it weakens some bodily function in the long run ? 70% people weak in a country will be very bad. It seems many people have long term consequences even after they are cured off CoronaVirus. Think of many people in country developing these long term problems : https://twitter.com/devisridhar/status/1268240519227981828 . . So if we race towards herd immunity blindly, it might turn out to be a disaster. We need to do more scientific research, understand whether immunity is long term / short term and accordingly we need to build onetime/recurrent vaccination regime. . With the recent success of Moderna in initial vaccine trials and confidence of Indian vaccine makers, I think there is a reason to believe that India will be able to build Herd Immunity around COVID19 in maybe 12–18 months. Till then we have to take precautions and maintain social distancing. . Adar Poonawalla on Twitter . This would be what helps us to build Herd Immunity. . Refs : . Here’s Why Herd Immunity Won’t Save Us From The COVID-19 Pandemic . https://www.modernatx.com/sites/default/files/RNA_Vaccines_White_Paper_Moderna_050317_v8_4.pdf . My answer to “Why is COVID-19 spreading relatively slowly in India?” . This was written during the lockdowns, after removal of lockdowns, the rate seems to have fastened a bit. Original answer here: https://qr.ae/pNKNR5 . As of now (26th April 2020), I would agree that India has been able to somewhat slow the growth of COVID19. . Some things I think which have contributed to it are: . (Most if not all) People listen to government. They don’t think that government is sitting and doing nothing and they are cooperating with whatever steps government takes, despite inconveniences. You can see the support for government at very grassroot levels. . | Indians deal with more communicable disease outbreaks than western countries due to tropical climate and high population. ( 2018 Nipah virus outbreak in Kerala - Wikipedia, 2019 Bihar encephalitis outbreak – Wikipedia ). They were never thinking of COVID19 as “just another flu”. . | Lockdowns have been very effective. Except for some idiots and a few religious zealots, the country has taken social distancing carefully. Poor people have displayed real fortitude. . | My answer to “How can machine learning aid in corona virus detection and prevention?” . Originally answered here: https://qr.ae/pNKNRS . I have written an extensive answer here : Muktabh Mayank’s answer to How can machine learning help against COVID-19? . I will just copy it so that you dont have to click the link : . AI and Machine Learning can help in many ways against COVID 19 : . Diagnostics : It can help doctors read slides, XRays , CT Scans faster by making things simpler for them by pre-categorizing scans as +, - , confusing etc. Here is a dataset to create a COVID19 detector in XRays : ieee8023/covid-chestxray-dataset . . Some relevant discussion on Fast AI : Notebook COVID-19 x-ray 3.7% error rate. Here is an RSNA paper to detect COVID19 from CT Scans: https://pubs.rsna.org/doi/10.1148/radiol.2020200905 . . . Triage: As you know that test kits for COVID19 are a important resource. Due to this their usage is rationed and triaged. A classifier can be trained to determine whether a person showing features should be tested or kept in quarentine immediately based on the locality they live in, their day-to-day interaction with people, their closest COVID19 case and other variables. An example project here: Machine learning for rapid triaging of Covid-19 at the front door of hospitals: request for data . . . Forecasting: Bayesian Modelling (and other Machine Learning models) can be used to forecast various effects of the pandemic. Here is some analysis by Thomas Wiecki analyzing growth. COVID-19 Growth Analysis . . SIR models used to model epidemics are not exactly Machine Learning, but rather simulations and differential equations, but its quite interesting to see for people interested in Maths and Data. . Discovering Drugs and Proteins: AI can help test different drugs proteins against COVID19. You might have heard of the Deepmind AlphaFold algorithm which came out a few days back: AlphaFold makes its mark in predicting protein structures . . Its now being used to predict protein structures for COVID 19: Computational predictions of protein structures associated with COVID-19 . Such a Just in Time discovery. Another way is using Generative AI to create new possible compounds that can fight the disease: Drug Discovery AI to Scour a Universe of Molecules for Wonder Drugs and TCS partners with CSIR to design AI based drug discovery process for COVID-19 - Express Computer . are some relevant pieces of news. . Sifting Available Research: Many high priority questions whose answers are needed to solve COVID19 could have already been worked on some scientists who probably don’t even know their work can save the world. This is an immense matchmaking problem. Text Mining/ Machine Learning approaches can help sift through huge research literature to find out what’s already known and can be used. There is a huge dataset on Kaggle (curated by some really serious people) where Data Scientists can participate and help discover answers : COVID-19 Open Research Dataset Challenge (CORD-19) . . . Quick Testing: A brilliant idea of doing a basic screening by recording sounds of breath may be achieved by Deep Learning. This can screen people on a smartphone, at their homes, for almost zero cost, without spending any money for procuring test kits, at whatever scale is desired. A project by NYU/FAIR to collect data has started here: Breathe for science . My answer to “How many countries are working on the COVID-19 vaccine? Has anyone succeeded so far?” . Originally answered here: https://qr.ae/pNKNR3 . There are over 120 potential vaccines for CoronaVirus being developed : Draft landscape of COVID-19 candidate vaccines . . . 10 of them are in clinical trials now. . What the person asking the question doesn’t understand is that unlike defense or nuclear engineering, “industrial” research in the world is almost never restricted by country boundaries. In fact, most research in vaccines is driven by financial incentive of making money for investors out of it. A lot of these vaccines are being developed by a collaboration of companies headquarters in different countries (and their research facilities located in sometimes countries where they are not officially from). Unlike say Socialist (Political Capitalist ?) China (whose public companies are sometimes still collaborating with other companies and countries), western Capitalism doesn’t work on National desires or needs or government policies, but, cater to simple supply-demand. Countries are incentivizing companies by making the financial outcome more lucrative at best : AstraZeneca receives $1 billion in U.S. funding for Oxford University coronavirus vaccine . . $1B, AstraZeneca must be US company right ? (Because Oxford sure as hell is not in US). No. . . So no, unlike how probably some countries (or people) might be thinking of making vaccine as a new “Space Race”, its actually just a bid to make a good early bird into market. . Let’s speak about 3 promising candidate vaccines :: . Oxford-AstraZeneca vaccine: . The above mentioned Oxford-AstraZeneca vaccine is one of the promising ones. It is a “Non-Replicating Viral Factor”, that is it doesn’t really introduce any multiplying genetic material of virus into the body but rather will teach the immune system to target other structures of the virus, like the spike protein. That is done by introducing weakened Adenoviruses (which dont cause any disease in humans) with material to produce CoronaVirus like spike proteins. . Coronavirus ‘spike’ protein just mapped, leading way to vaccine . . It has been proven to be safe for humans in first few trials and larger trials are now starting in Brazil. (The current epicenter of the disease). . Brazil to help test Oxford coronavirus vaccine . . However, we still don’t know if medicine works. All we know is that it is safe. It doesn’t work well in monkeys and if it were an ideal world, the vaccine would not have been tested anymore. . Potential Oxford vaccine fails to prevent coronavirus spread in monkeys, but protects from pneumonia . . You now understand probably why we need many parallel vaccine candidates. (And also understand that the most promising vaccine we have is ineffective on monkeys with COVID19 infection). . Moderna vaccine: . The other vaccine which is promising is the Moderna mrna based vaccine. . Moderna is a US startup (or you can call it a relatively smaller public pharma company, quite tiny as compared to other big Pharma involved). . The clever thing about Moderna vaccine is the technique it uses. It literally genetically engineers human cells to produce material that would trigger an immune response to COVID19 infection. (Which is done by infecting humans with a genetically engineered bacteria). The genetic material introduced into humans for producing this immune response for CoronaVirus is not actually its DNA/RNA but rather its mRNA (mitochondrial RNA). This makes sure that no replication of CoronaVirus genetic material occurs (mrna doesnt cause replication), while the immune cells learn to recognize the CoronaVirus components and kill the cells containing them. This technique is new and has never been used for any vaccine before COVID19. . The initial results (according to Moderna and Dr. Fauci) seem to be promising. Moderna Announces Positive Interim Phase 1 Data for its mRNA Vaccine (mRNA-1273) Against Novel Coronavirus | Moderna, Inc. . . However, that is just data that company has released. As of now, I don’t know about if they have an official publication for the results of study. That is what a lot of people are complaining about as well. . Vaccine experts say Moderna’s Covid-19 data leave big questions . . Moderna has started its Phase 2 trials and Phase 3 trials will start in July. . Moderna starts dosing in Phase II Covid-19 vaccine trial . . Moderna to begin phase 3 trials in July, Oxford to test Chadox1 on children: All you need to know about COVID-19 vaccines in the works - Firstpost . . Sinovac Vaccine: . Now lets see about the Sinovac vaccine. Sinovac as it sounds from the name, is a Chinese public company. It has more than one candidate vaccine but there is one for which it has made some public data available. Rapid development of an inactivated vaccine for SARS-CoV-2 . . The paper claims that SinoVac vaccine cures monkeys from COVID19, something that Oxford vaccine could not. . The vaccine works by first multiplying and then killing SARS-COV-2 viruses by dipping them into an organic chemical and then injecting the dead virus into humans to make immune system learn to fight COVID19. They have started clinical trials too: . Three COVID-19 vaccines approved for clinical trials . . This vaccine is also being tried outside China. . Coronavirus: China’s Sinovac Biotech in talks to test Covid-19 vaccine globally . . If you look at the list of potential vaccines, there are vaccine candidates from Europe, Japan, India etc. apart from famous ones like those from US, UK, China based companies. . My answer to “Is hydroxychloroquine hype or hope?” . Originally answered here: https://qr.ae/pNKNRd . From what we know right now, HydroxyChloroquine (HCQ) is one of the most practical methods we have to prevent COVID19 in frontline workers and serious patients. . There is some indication that it works : Hydroxychloroquine and azithromycin as a treatment of COVID-19: results of an open-label non-randomized clinical trial . | . It is actually one of the prescriptions in recommended approach to ICU management in COVID19: Intensive care management of coronavirus disease 2019 (COVID-19): challenges and recommendations . Its side effects are known. Proper trials have been done. So doctors can calculate how much of a tradeoff it is to prescribe. . | It is cheap and can be produced in large quantities. Thus can be used by poor countries, who really have no other alternatives. . | Other Anti-Virals that have been proposed have similar “not sure if it works” results with no clinical trials and studies on side effects. . | If this question was asked in context of latest Lancet study : Hydroxychloroquine shows no virus benefit, raises death risk: study . . Link to the study observations here: Hydroxychloroquine or chloroquine with or without a macrolide for treatment of COVID-19: a multinational registry analysis . The issue gathered steam and WHO paused HCQ trials and France and a few other countries stopped prescribing HCQ. (India/Brazil etc still continued the prescriptions). . This study seems to have some grave issues : Scientists raise concern over hydroxychloroquine study . . The dataset for study was not exactly public and was not from a randomized trial. After may scientists expressed concerns, Lancet actually issued doubts about the published study itself: Expression of concern: Hydroxychloroquine or chloroquine with or without a macrolide for treatment of COVID-19: a multinational registry analysis . As of now, WHO trial for HCQ has been restarted (and its result is what we should believe about efficacy of HCQ) and HCQ continues to be prescribed. . The Lancet doubts over hydroxychloroquine study see WHO restart trials . . So, for now, we still dont have enough data, but given data right now, it seems HCQ is a good bet. Time will tell. . My answer to “How plausible is it to implement Sweden’s model of herd immunity in a country like India to fight COVID-19?” . Originally answered here: https://qr.ae/pNKN88 . Sweden’s herd immunity model was a failure : . “Could Have Done Better, Clearly,” Says Man Behind Sweden’s COVID-19 Plan . We should have done more, admits architect of Sweden’s Covid-19 strategy . . Sweden’s coronavirus plan is a ‘failure’, opposition politicians say . . India’s lockdowns on the other hand were quite successful. . Lockdowns may have averted 3 million deaths in Europe by curbing Covid-19: Study - Times of India . . Lockdown saved as many as 71,000 lives, claims ministry . . You can generally see that India’s Corona curve had a consistently falling doubling rate due to quickly implemented lockdowns. . . Source: . Prof Shamika Ravi on Twitter . Compare it to other countries like US and Italy where an immediate lockdown was not imposed. That saved many many lives, unprepared people are the most vulnerable in a pandemic. . Although the condition is getting worse in Delhi (where most of the media is an thus reports on television have become gloomy), as of now, India seems to be recovering as a whole : . . Source: . Prof Shamika Ravi on Twitter . Look at other possible paths the curve could have taken. A strategy like Sweden would have required many-many deaths in the country before the disease could have been contained. . Herd Immunity without vaccine is a joke. . My answer to “Is the Indian government adopting a herd immunity strategy by easing up lockdown restrictions?” . Originally answered here: https://qr.ae/pNKN8G . No. Herd Immunity is not a practical solution : Muktabh Mayank’s answer to What is herd immunity, and how can it be effective for countries like India?. Herd Immunity means exposing (almost) everyone to the virus and waiting to see who comes out alive, that would be disastrous. . What Indian government is trying to do is to keep the infected numbers to the minimum possible as long as a vaccine/cure is not found out. We had early lockdowns to try: . If we could just crush the curve. That is have a flattened curve in areas with virus going up. Stop movement of people and make sure the rest of the country could reopen. Eventually the hotzones would cool off too. . | We could produce enough PPEs, Hand Sanitizers, HCQ etc so that we can look after the sick. . | Here’s what Crushing the curve is: . Immediate Action . | Travel Restrictions . | Lockdowns . | Test + Isolate . | Wait for curve to slowly go down. . | Prof. Yaneer Bar-Yam explaining it below : . . https://youtu.be/fXUVFqKKcBM . While for countries with smaller population, 1 is easy to achieve, that is the infections can be brought down to zero just using lockdowns. it turns out for countries with large populations (We don’t know much about China, but everyone below China in population like India, Indonesia, US, Brazil, Russia…) the amount of lockdowns required is longer (just due to large numbers) to crush the curve altogether. So for example, a country with small population like New Zealand needs to wait lesser to crush the curve than say Indonesia. The patience of people will die after sometime and they stop supporting the lockdowns. India started seeing on-foot movement of people despite all transport disabled and UBI announcements. Public servants and representatives were afraid of lighter government coffers , businessmen became restless and people were slowly more afraid of economy tanking than the virus itself. One cannot thus continue the the lockdowns and travel restrictions. So we are trying to have a midway approach : Reopen and try to restrict infections despite of that. . What we have been able to do is achieve 2 well: . We now have capability to test lot of people: India: COVID-19 tests per day | Statista . . We now have enough PPE capacity : . India becomes world’s second largest manufacturer of PPE body coveralls, next to China: Government . . We have enough masks and sanitizers in market (remember 2 months back ?) . However, it seems that community spread has started in Delhi and Mumbai while we have reopened these cities. Both of these cities have very high population density. . We might have lockdowns in Delhi/Mumbai again while rest of the country reopens. .",
            "url": "https://muktabh.xyz/2020/06/10/Observations-on-ongoing-coronavirus-pandemic.html",
            "relUrl": "/2020/06/10/Observations-on-ongoing-coronavirus-pandemic.html",
            "date": " • Jun 10, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "When To Run Away And Not Look Back At Your Current Software Developer Job",
            "content": "Some instances where I advised Software Developers to run away from their employer on Quora! . Q. I work for a startup, our CTO is a big fan of Golang, he insists to use Golang for every projects, including machine learning projects where Python is the de facto standard, what should I do? . Originally Answered Here: https://qr.ae/pNnZby . Run away and don’t look back. There is going to be no use working under someone that fanatic. I am a fan of Go as a language myself, but this is a bit too much. There is no doubt a need of uniformity in the codebase and there needs to be a fixed stack, but I don’t think it is common sense to hamper productivity so much so as to start using esoteric Machine Learning frameworks in Go. . Instead of working on Machine Learning, most of the time will go to try out and fight/enhance Go’s nascent Machine Learning ecosystem. While some people will love enhancing Go’s Machine Learning capabilities (I think there is a decent community), its not something every Data Scientist would want. Also as a startup there will be tight deadlines and working on places where the libraries aren’t optimized will be a nightmare. . No go according to me. . Q. How do I survive in a startup with undocumented code base? . Stories like this are a norm. I’m a fresher. We’ve a large code base running for over two years. I was told to implement an interface which was committed over a year - and there was no documentation at all. I asked about the functioning of the individual methods to which I got a reply that I ought to look at examples where it is implemented. Is it normal? Does everyone have to read un-commented code for hours while the person who’s originally written it could explain it in five minutes? . Originally Answered Here: https://qr.ae/TfxZ43 . A lot of startups dont have formal documentation, but that doesnt mean young employees are left on their own. . 3 subquestions you asked : . Is it normal? No. This shows poor engineering standards of the company. Your PM and Lead are not doing their job well. Most companies either have documentation or KT (knowledge Transfer sessions) before a new Engineer takes over the job . Does everyone have to read un-commented code for hours while the person who’s originally written it could explain it in five minutes? After they are given an overview of the project, people sometimes do need to read undocumented code, but there needs to be someone whom they can approach for guidance. Maybe their lead or a senior developer in the project. . What should my approach be? Run. All I can understand is that the company you work in wants you to be a code monkey. Do you think such mess of code can ever scale ? If you want to be a good engineer, join a place which has some engineering practices. . Q. In my first job in a new industry, I am underpaid with no sign of a raise coming from my current employer. However, I am learning quite a bit/improving consistently. How does one remain focused on continuous learning for now and more money later? . Originally Answered Here: https://qr.ae/pNnZOV . Talk to your employer and understand what timelines they have in terms of promoting you/giving you a raise. You need to understand how your company is doing. There are many possible scenarios: . There is no reason your employer cannot give you (justified) raise pending from a long time if your company is doing good. They are just bad people to work for if they reject a genuine raise in this case. . | If the company is not doing well and you are learning a lot at your work, you need to understand what is the marginal gain in learning (I understand that workplaces with uncertain futures are great learning experiences) as compared to a stable salary you are being offered somewhere else. Are they allowing you to cash out on your learning by generating your own client interface/networks or publishing papers/blogs/patents ? Remember, just learning isn’t enough, putting it out there also is. You need to understand till what level you want to continue learning (Specialization is a field only pays off for a certain level). . | If the company is not doing too well and you feel it will get better, you are sharing the risk of the company. In that case, you should ask for share in gains as well (equity, promised bonuses etc.). Set a timeline till when you will wait for the company to do better. . | The fourth scenario where the company is not doing well and you dont expect it to rebound, quit. They would have fired you if they did not see you get better, they might give you a pink slip to cut losses in future. . Q. How can we approach a product-based startup even if we’re ready to work without salary for experience and a full-time job in Bangalore? . | | Originally answered here: https://qr.ae/TqMatO . (My startup is not based out of Bangalore, so you can consider this as a third party opinion). . How startups work and how people outside might visualize them is maybe very different. Most people who don’t know a startup inside out, relate them more to the large companies like Infosys, Google, Amazon etc. (and now probably Flipkart, Ola ?) , which they are more familiar with . . Any startup’s ideal employees are: . Self taught (or slightly experienced) beginners (not novices) who will be able to take low salaries an deliver tasks assigned to them. The work culture is flexible, so fitting in doesn’t matter, people have to deliver that’s all. (Entry Level) . | Smart people who are willing to compensated by equity instead of salary and can lead employees like 1 (above) into building something that scales and can raise money. (Senior) . | A large company’s ideal employees are: . Non-Experienced people/novices who can join and learn the company’s work culture and methodology and learn skills to deliver accordingly. Company can afford to spend good money here and sometime novices in big companies are better paid than beginners in startups. (Entry Level) . | Then hierarchy wise the company has various openings with high salaries where they acquire senior people, including even the C-suite. (Senior Positions) . | Apart from salaries (which are typically low cash + high equity in startups and high cash + low equity in large companies), there is a second difference at the entry level hirings : Startups need people who have somewhat a non-zero level (beginner &gt; novice, a beginner for example will be able to write a simple web service in Python, while a novice will just know Python syntax) of knowledge and can learn on the job, large companies prefer novices whom they can train in their own efficient way. Remember startups are optimized for speed, large companies for efficiency. . Don’t be willing to work for free, try to get to a level where you can get an entry level job is what I will recommend if you want to work in a startup. It is not that hard; do a couple of online courses, don’t pay, just audit or just read good books and get yourself slightly above the curve. . The other way can be , take a novice level job (given you are a novice and not a beginner) in a large company where you are getting the profile you want and get some experience by their training. You can join a startup later if you don’t find their culture good. . If you are beginner/advanced beginner who is applying to work in startups for free and not getting calls, improve your medium (switch to Hasgeek/AngelList etc) , because this is not really possible if you are doing it well. .",
            "url": "https://muktabh.xyz/2020/05/28/When-to-run-away-and-not-look-back-at-your-current-software-developer-job.html",
            "relUrl": "/2020/05/28/When-to-run-away-and-not-look-back-at-your-current-software-developer-job.html",
            "date": " • May 28, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Replies To Questions On Ai Ludditism",
            "content": "Some thoughts around prevalent AI Ludditism [From Quora answers] . I have tried to clarify some common fears people have around AI eating their jobs in my Quora answers. . My answer to “Artificial intelligence will or may lead to an unanticipated crisis if it starts to code itself? How true is it?” . Originally answered here: https://qr.ae/TSC6dR . Chill!! People who are asking such questions need to first of all stop worrying and stop reading media articles trying to scare them. . We are decades (maybe centuries) away from totally automating tasks which require such high level of mental capability. Present Artificial Intelligence can at best approximate tasks which require 2–3 seconds of human decision making that is all. Also most AI we have developed right now is not Artificial general intelligence - Wikipedia . (the one which you watch on movies) but task specific algorithms. We have not even created Terminator/Skynet 0.0.1 yet. . To answer your question directly, it might be a problem (with some low probability) if AI starts implementing a better AI itself, thus increasing its capability at a superhuman rate making humans obsolete. But this is like hundreds of other low probability doomsday scenarios like an Alien civilization attacking and colonizing us or Earth’s capability to support life getting over. So no point worrying about it in real life. . My answer to “What is Deepfake technology?” . Originally answered here: https://qr.ae/pNnxiL . Deepfake is essentially creating fake images/videos/audio/text using Deep Learning techniques. . For example, if you remember a recent viral app which used to create images of how a person would look if they were old or applied makeup, the images it was creating were fake images generated by AI. . However, the term “Deepfake” is generally used for describing negative usage of such technologies. . So you can have someone’s face placed in an objectionable photograph, someone being made to speak fake things they never said in a video and a fake audio in someone’s voice or just a fake news article using Generative Deep Learning algorithms. . For example there are websites where objectionable videos of celebrities are created by morphing their faces into existing pornography using Deep Learning. There is also danger of a video being made with a politician being made to say something that they have not using such technology to sway the public opinion. . It isn’t that such fake photographs or videos or audio cannot be created by humans. They can be and have been created in the past and even now. Just that Deep Learning algorithms bring “automation” to it, that is they can now be created in large quantities without human involvement. . I will put some examples here which you can see and understand how AI can generate video/image/text samples : . Generating Videos Using Deep Learning . First order model . : . Video: . https://raw.githubusercontent.com/AliaksandrSiarohin/first-order-model/master/sup-mat/vox-teaser.gif . Generating Images Using Deep Learning . Semi-supervised StyleGAN: Disentanglement is through mutual information loss. Propose new metrics for measuring disentanglement in generator. Take-away: small amount of supervision is enough for disentanglement and high-res generation @NVIDIAAI pic.twitter.com/FDh26WbiQQ . — Anima Anandkumar (hiring) (@AnimaAnandkumar) March 12, 2020 . Animesh Garg on Twitter . Generating Text Using Deep Learning . Better Language Models and Their Implications . . My answer to “Should we be worried about deep fakes and the misuse of facial recognition?” . Originally answered here: https://qr.ae/Tx6CUl . I think the only aspect of Artificial Intelligence that can disrupt our world for a very long time to come is going to be DeepFakes. The reason is not because the technology is itself very harmful, the reason is because humans are emotional and don’t really put a thought before believing and sharing videos or voice messages. You could basically generate photos , videos and voice clips of a person doing/saying whatever you want using these techniques. I will not be surprised if fake media created by these technology be used to instigate violence or bad faith. In a world where fake news is widespread and fake news busters can spread fake news too, it is going to be big challenge to tackle Deepfakes. . The misuse of facial recognition is actually somewhat fearmongering and ludditism. It probably makes the world somewhat less private, but every technology since the invention of cameras has done so for a very long time and its a continuing trend since years. I think the probability of using Face Recognition for bad purposes is not that high. That said, I think there are already regulations in place in various countries to make sure Facial Recognition cannot be used to harm people. . My answer to “Why Deep mind AI of Google failed to answer 1+1+1+1+1+1+1?” . Originally answered here: https://qr.ae/pNnedF . Many assumptions in the question appear wrong: . Deepmind is a company, its not an AI. . | The way you refer to AI, it feels like you are talking about Artificial general intelligence – Wikipedia. . Most AI we have in the world (and most of what Deepmind builds) is Weak AI - Wikipedia . | AGI (Artificial General Intelligence) is a theoretical future where computers can learn any new task when presented to them like humans, is decades if not centuries away. Weak AI means a Computer needs to be programmed to perform one task, like detecting cavity in teeth or playing Atari games. . | . Weak AI variant for problems like “1 + 1 + 1 … “ exists. That is simple mathematical expression parsing and evaluation. What Deepmind was trying to do was to use a Weak AI model generally used to look for features in language (LSTMs are the algorithm) to solve mathematical problems. All it tells is Weak AI algorithms to extract features on Natural Language cannot learn to solve Mathematical problem as of now. . | . Please don’t read pop sci articles on AI like these: Google’s DeepMind Failed A High School Level Math Test: What Does This Mean? . They are just not informative enough and misguide. . My answer to “What you think about “Data Scientists Automated and Unemployed by 2025?” article?” . | | . Link to original answer : https://www.quora.com/What-you-think-about-Data-Scientists-Automated-and-Unemployed-by-2025-article/answers/16871059 . The so called Data Scientists who use off the shelf Machine Learning algorithms on simple data WILL be automated pretty soon, infact Amazon/Azure/Google ML services already do so. To be frank, calling sklearn.fit_predict with different parameters is not really hard and is kind of repetitive. The real world is slightly different, A lot of real world Data Scientists are actually Data Mungers, who clean/transform the data (which is really hard to automate), and then Hyperparameter adjusters who apply black box algorithms on top of it (which is easy to automate). Other easy repetitive tasks, which involve simple repetitive work and involve humans for the hack of it (say Data Entry Operators, Customer Support chat people, ) are being automated at a steep rate too. Surprisingly, some aspects of art (some form of painting, music, lyrics writing) is being automated too, which I thought was impossible to. The day to day tasks of actual Data Scientists, say working at Facebook AI research and Google Brain (writing different Artificial Intelligence agents) will be one of the last to be automated, as it is generally very hard. So I think they will be one of the last in last in the  line of losing “survival of the fittest” battle to Machines. A time when Machine can deduce algorithms is still far off in future. . My answer to “What will be the need for humans if we automate everything with machine learning and robotics? What will humans do in the future?” . Link to original answer here: https://www.quora.com/What-will-be-the-need-for-humans-if-we-automate-everything-with-machine-learning-and-robotics-What-will-humans-do-in-the-future/answer/Muktabh-Mayank . Why is it necessary for humans to work ? Do any other species of plants and animals work jobs ? Don’t other species live ? Is the only purpose of human existence to make Excel and Powerpoint sheets or write Python code ? These are deep metaphysical questions which are more philosophical and have no real (only theoretical ) answers. Also this is not my answer. . The more practical answer is that automation has always been coming, jobs have always been automated. Shoe Makers were automated by factories and chariot drivers and horse tamers were automated by cars. What always happens is new jobs were created every time (factory workers, car drivers) requiring lesser number of humans, so that humans could engage in more intellectually demanding fields. The same is happening now, with incoming AI technology, jobs are changing. The difference is that while it took generations earlier for a change to reflect, people will see drastic changes in their lifetime (that’s probably the only challenge I see, people will not really be able to “settle” on a career for all their lives pretty soon and will require to learn-unlearn many times in their lifetime) . The (wrongful) fear is because we see only one aspect of it, not the other side. AI does automate stuff, but sum of human achievements is not a Zero Sum game, it will grow larger. While you might not be required to enter data in Excel (one random example) searching web due to AI, a bigger intellectual challenge can be taken over by same person than Excel data entry (like say solving Cancer). . My answer to “Will data science and machine learning get automated leading to lesser opportunities for data scientists” . Originally answered here: https://www.quora.com/Will-data-science-and-machine-learning-get-automated-leading-to-lesser-opportunities-for-data-scientists-as-per-https-www-datasciencecentral-com-profiles-blogs-data-scientists-automated-and-unemployed-by-2025-update/answer/Muktabh-Mayank . Yes. (2025 is not the date I think its going to happen, but its inevitable and will happen in near future). They will be to a good extent. So will be Software Developers, designers, manual workers, teachers, linguists, musicians, game developers etc,etc. There are already rudimentary projects like Turning Design Mockups Into Code With Deep Learning which can turn a design mockup into HTML/CSS code, carpedm20/ENAS-pytorch which can design neural networks without a Data Scientist, Why AutoML Is Set To Become The Future Of Artificial Intelligence , system which can generate new characters for games, Microsoft AI can translate Chinese to English just as accurately as humans , Baidu’s Deep Voice can clone speech with less than four seconds of training | Computing and multiple such projects. . OpanAI’s new project can generate programs given specs : https://www.youtube.com/watch?v=utuz7wBGjKM . . Look at the artificially drawn faces by latest GANs , designers will find it harder to compete with the new quality. https://youtu.be/XOxxPcy5Gr4 . . AI will impact every job profile which exists as of now, Data Scientists no exception, automating some or a lot of work people spend their time on. For a lot of time these systems will become a &lt;Man + Machine&gt; AI systems rather than just a Human working before stuff is totally automated. So its not like everyone becomes redundant day 1, but they will eventually. . Full Automation of any field is going to take way longer than 2025 IMHO. That said, yes a lot less people will be needed for the same task as of today. Then what will people do you ask ? newer more complex tasks. . Automation is not a new phenomenon. Think about the railway breaks a long time back: https://youtu.be/EEUkmP2nyxo . . So much work was once needed to just stop the train. A lot lesser work is needed today to run/stop the train and not just that, slowly trains are moving towards full automation, but right now they are in a &lt;man + machine&gt; stage. A lot of jobs will stay in this phase for sometime before full automation kicks in. But unlike railways, which take generations to move from one stage of automation to another, AI is causing changes at a phase at a very high rate. . What is the effect on a general Data Scientist (or any white/blue collared worker for that matter): . Adapt to AI. Automation has started, but AI aided jobs will stay for a few more years than non-AI jobs. So while no plain X jobs by 2025, X + AI jobs might be around till 2030. . | Things wont be like earlier generations where one skill learnt gets you a job for entire life. One needs to be open to learning new skills and get started in the middle of life. . | Average level of education needed will be high. Think of it, 50 years back “High School” was all the education needed for most jobs. Now its somewhere between high school and graduation. Masters and Research might look like the next frontier, but these degrees are too slow and broad. Coursera like courses will become more important in catching new skillsets. You might already see people doing that a lot. . | With more uncertainty in jobs, millenials probably will want to be a less “spend-y” and more frugal. You can see things happening already 6 reasons why more millennials aren’t buying homes and will actually increase. AI is just a trend in a longer cycle of Automation and millenials are at a point in history where education+society was according to old norms but automation has reached a point where jobs have become uncertain. Younger people will be smarter. . | My answer to “Should facial recognition technology be banned considering it can do more harm than good?” . “It can do more harm than good.” How is this proven ? This is just a subjective opinion. If we were to make regulations on subjective opinions, we would ban many things just because people thought they are bad. Unfortunately, Humans do react to emotionally and based on opinions. we have regulated away (or are trying to regulate away) innovation in fields which can potentially solve the biggest problems the world is facing right now, because we were made to emotionally believe that the fields are bad, just like how the OP thinks about Facial Recognition today. . Let me give some examples : . Research in Nuclear Engineering and making reactors has been sidelined and demonized so much that very less innovation than expected has happened in these fields. We could have by now potentially removed all polluting coal power if we would have innovated well and global warming would not have been an issue maybe. But no, because people are made to believe that Nuclear power itself is bad, our democratic institutions have neglected this field. There is no doubt about the fact that Nuclear reactors malfunctioned in past and there were nuclear weapons. The correct way should have been to promote Nuclear technology that is less risky and cannot be weaponized. But that would not have struck a chord with the armchair smart people that run the world as its a boring pitch. . | That’s not the only thing. We have to feed everyone in the world and we are willing to promote insects as a potential protein source than promoting work on GMOs. The most sensible solution would have been to estimate what is the total capacity of Earth to sustain human population and check the rise accordingly. Dont push something you don’t know the response of. We don’t do so, because that disregards human freedom and also would lower the return on our financial investments. When we don’t understand how to feed these new people we would either build a class exploitation theory (which is not entirely wrong, but that’s not the only reason) or just ask them to eat insects for protein. A better way to solve this would be by making more resistant crops using GMOs. Genetic Modifications is something humans have been anyway doing by force breeding plants and animals, but in a slow long term way. All technology enables us to do is to make the process faster. Of course, no one is denying potential risks of GMOs and we should regulate GMOs for these, but building a culture and opinion around “organic food” and demonizing them completely is not what would be sustainable. . | . Anti-nuclear movement - Wikipedia . . Genetically modified food controversies - Wikipedia . Things still move in background but very slowly for these two and many such fields which common public feel the fields are bad because their security is threatened. There is no doubt that regulation is needed to protect public security, but banning fields of science and demonizing them are modern equivalents to Book burning - Wikipedia . . Stupid and Luddite. . Now, let’s come to the current question. “Should Face Recognition be banned altogether ?” . . Can you guarantee that banning it would stop government and people in power snooping on innocent people ? . | Can you guarantee that all the lives Face Recognition surveillance saves from terrorists and wrong doers will still be saved ? If no, are the potential lives saved by this technology of lesser importance than your own life ? Why should they go to waste ? . | All AI phrenology is snake oil. Phrenology - Wikipedia . | . AI to determine the right candidate for the job, AI to determine gender/sexual orientation, AI to determine criminal action. All these fields are snake oil from what I understand. So if you are making this as a case against Facial Recognition, you are reading one or both out of hyped up media and bad research. . | I have no doubt that there are potential wrongdoings that Facial Recognition can be used for. Stopping that by regulations is why we elect people into parliaments and legislatures. I really like how the cigarette companies are required to put photos of the potential bad effects of their products on packets by regulation, fantastic trick of regulation. There is then gatekeeping regulation with thick red tape so that only big firms with lawyers can deal with. That is another way how the negative hype can be used to restrict innovation. . There should be restriction of bad practices. But if people force them to take stupid book burning decisions, we are destined to not cross the great filter. Great Filter - Wikipedia . If this answer feels wrong and boring, that is how most real world issues are : Complex and not solvable with one line blanket statements like : “Ban X” and “F**K Y”. .",
            "url": "https://muktabh.xyz/2020/05/23/Replies-To-Questions-On-AI-Ludditism.html",
            "relUrl": "/2020/05/23/Replies-To-Questions-On-AI-Ludditism.html",
            "date": " • May 23, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Views On Indian Startups",
            "content": "Some Thoughts about Indian Startup Scene (As various answers to Quora questions) . My answer to “How can you define the Indian startup economy? . Originally Answered Here: https://qr.ae/TDM7li . India is in a unique position demographically and economically to create many different types of companies. This demographic dividend of youth creates unique opportunities : . India’s cost of living is low, so you can still get relatively better talent at a certain wage. . | India’s population is growing and many people are entering into the workforce. Given these people are trained well, a supply-demand gap will not arise for certain time period and hence wages will remain relatively stable for a long time time to come. This makes sure doing more and more innovation doesn’t get costlier. . | Indian government is no longer a Soviet style planned, capitalists-are-pig preaching economy. Same with people, people no longer wanted to work in stagnant government jobs where hard work had no rewards and the most optimal behavior was to work just enough to not get into trouble, but rather to make money with hard work and enjoy their lives. . | That said, a lot of these people will start getting good wages making a larger middle class. This creates a larger market where you can sell goods and services making more people get good wages and increasing the market even more. . | This is a great opportunity, with a window between years 1990–2050. . While initially we let large companies come to India and use India as a talent pool (and market) for a very long time (when I completed my engineering in 2012 at BITS Pilani, working for a large multinational was the top choice, most of my batchmates work for a multinational in India or abroad), giving employment to a certain number of people creating a primary new middle class, we cannot hope to sustain our growing population with these multinationals who bring only selected jobs here. The first middle class we created with this capitalist boom of 1990s and 2000s also created a stronger demand (market) for goods and services and created a talent pool. This can do wonders . . Let’s see what happened when there was no startup economy in India. A very good period to think about this was the 2000s. We already had a middle class who believed in neoliberalism/globalism very strongly and we were using American products like there is no tomorrow. Think of it, no big search engines, social networks, Electronic manifactures and Mobile OS came out of India, None. We were really happy using Symbian, Orkut, Facebook and others. Think of the amount of technical expertise and talent pool these companies would have created if India had its own Baidu, Yandex, Android or Xiaomi. This would have created way more startups and jobs and market than what we have right now. We missed out ! Governments did not have confidence to put policies in place which could help benefit our ecosystem or they maybe did not realize the power of ecosystems and economies of scale. . Indian Entrepreneurs of 2000s and early 2010s had to prove their mettle by sweat and blood. They proved that companies could be built in India, large ones. Zoho, Infoedge, Freshworks, Flipkart, PayTM, SnapDeal and startups of that generation deserve respect just for standing up and building up a company. That is what gave confidence to government that Indians can build large companies and confidence of next generation of entrepreneurs that its possible to make it big with some risks and made people believe they can spend money on an Indian website or app. The fellows and contemporaries of these entrepreneurs who saw their success came back from their high paid multinational jobs to join the startup ecosystem and the story began. . When we serve our own market, we create an ecosystem: . And let’s see what happened when we have an startup ecosystem (my preferred term instead of startup economy). Any technology trend has 3 steps -&gt; 1. Early Developments , 2. Growth and 3. Consolidation. With our startup system maturing, we still haven’t reached the level of doing Early Developments of technology trends (say food tech, coworking, ride hailing, O2O etc did not start in India but still in US and China), but already at growth stage we can build companies which can cater to our markets specifically. This adds new bigger startups to our ecosystem all the time. These bring in new talent that is economically powerful that can drive the next wave building even larger startups. . In first wave of startups like Search Engines and Social Networks we were so behind that had no Indian companies, in the next wave like ride hailing and e-commerce, we had an Indian counterpart racing with a foreign high-growth startup from outside (Flipart/OLA) and in the next step, we have all Indian companies in fintech and hotel space and foodtech (Oyo / PayTM / Swiggy and Zomato/ so many lending startups). . If you have not mentioned, we are progressing very fast in not a very long duration. . How this contributes to building better ecosystem ? While operational jobs will always be in India for an Indian and Foreign company, that is foreigners will seldom deliver food in India, high worth and innovative jobs come to India with Indian companies. For example, way higher ratio of product managers of an Indian startup will sit in India than product managers of Foreign startups. This adds way more to ecosystem as for the next innovation India will be more prepared and maybe Indian ecosystem is so early to some technology trend that we have our own google in that space. The other thing is that these high innovative individuals earn much more and create a more powerful market than just operational people. . You can also see the progress in technology development too. I consider Infosys to be the first successful Indian startup in software. From primarily deploying software as to how old software companies of India worked to making cheaper variants of successful software products, I think we are soon going to see the next break through where Indian Software startups which dominate by their innovation will emerge. . Innovation follows large businesses and ecosystem that can invest in them: . Once there is demand and market (people willing to adapt and government not-interfering or better helping) and supply (a talent pool that can build services that can cater to demand), economics happens. In 2000s, There was high respect of “multinationals” in India and people wanted to buy/use their products, this created a huge market for multinational corporations in India and frankly, they are monopolies in India, even bigger market shares than in their own companies. Think about Google, Facebook, Suzuki. . However, look at the long term repercussions. I will talk about software because I know the space well. India still doesn’t know widely how to build Server Farms, hugely scalable software tools (have you heard of an Indian mapreduce ? an Indian Golang ? Indian Tensorflow ?), despite giving an opportunity to scale these companies so much. These companies now have so much edge that probably any Indian Search Engine / Social Media innovation at best will be a copy and be months if not years behind in tech due to lack of ecosystem. A lot of these tools have their parallel in China and Russia which have their own ecosystems. Not saying that using non-tensorflow is a must, but knowledge of building tensorflow-like failed software also helps drive next step of innovation. That knowledge needs to stay in ecosystem. India had no ecosystem, so no one stayed back which created a bad image and lead to further brain drain. . High innovation thing like say building a Tensorflow requires a very very strong pre-existing business that can take load of R &amp;D on top of their nominal business. Only old very successful companies can do it. They will hence create an advantage which is very strong and that cannot be taken away from them. Moat is the terms startups have for it. Tensorflow innovations will slowly make companies using the tool migrate to Google cloud just by the features. This is going to be a big business for Google in the future. . Our companies will be able to do it locally after they grow really big and are able to attract our top talent to stay and in fact bring top talent from outside. Again, all this top talent, will be very highly paid and will spend their money in the country, making our economy bigger. Operational jobs are never going anywhere too. . Why some people don’t like startup risks and prefer the older “safer” way : . (I observed this trend in other answer to the question and thus am adding this heading which is not really relevant to the question) . Well because the old multinational way, a few people of India got employment in large stable multi national companies which were expanding. A small set of relatively safer jobs were created. A company in early phases of a technology trend has more jobs, but these are more volatile. So a section of people who would have the advantage of the safer jobs of multinational might not like more volumes of higher-uncertainty jobs getting created. We have to leave this Soviet style mentality behind. . My answer to “Why are huge Indian tech startups bleeding losses?” . Originally Answered Here: https://qr.ae/TleOX5 . Because they are not meant to make profits in their initial days. . Indian media (and self anointed experts most people listen to) is quite old fashioned about running a company and still tries to put everything in perspective of the 1990s, the world has moved beyond that to what I now call the “Amazon model”. Other companies which have similar approaches are FaceBook, Uber, Turo, AirBnB, (Indian startups which you are probably talking about in question -&gt; ) Oyo, Swiggy, Zomato and so on. “Smart” answers like “they are not innovative enough” I see here have to understand some of the world’s largest companies have been formed with this strategy. All these startups (not all startups btw, many have different routes to growth) are following is a well formed strategy successful companies have used. Investors have put their money for exactly the same purpose in these companies : burn and grow big. . These companies will invest for a very long time to build a platform first, will come up with a large set of users and then this economy of scale helps them build many products and solutions they can monetize to invest again in growth, this is going to be a cycle till the company keeps growing fast in valuation. . So for example, Amazon was building e-commerce, then build a scalable could service to scale it up and then built AWS which they now monetize. Similarly Ola build a ride hailing service, then built a wallet to pay for that service, then will use that wallet to get into fintech and so on do forth. . You have to understand that investors have not put money into these companies for dividends on profit but growth in valuation of their equity and they are actually all growing rich by burning the money. They are doing exactly what their investors have put their money in for. This is not a sign of weakness or being unstable. . If you are working at such a startup company where they show consistent losses and you are not sure how to differentiate between whether its a good company or not , find out information about “How fast is the valuation of company growing ?”. If the valuation is growing fast and well, the company is working as expected, there is no problem ! . My answer to “Why do 90% of startups fail in India?” . Originally Answered here: https://qr.ae/TVQM9c . 90% startups fail EVERYWHERE. There is nothing special (or worse) about India in terms of startups. . Startups fail because of following reasons most of time : . Working on a business idea which founders cannot convince others about (investors to invest in idea/ customers to buy a product/ users to use a product). . | Start scaling and spending before Product Market Fit. . | Disagreements between founders. . | Not being to deliver what they promise. . | There can be many many possible reasons why startups fail, everything needs to go right for a startup to work. . My answer to “Can a startup become successful by outsourcing 100% of its employees?” . Originally answered here: https://qr.ae/Tlev1W . Apart from giving out very small non-repetition tasks, I personally don’t think a startup should outsource. . Possible things you can outsource (with good IP agreements) : . Designing websites and logo. . | Writing one time programming modules like say one specific task for one specific client which your product team won’t have to work on. . | Headhunting for specific profiles, organizing hackathons etc. Things that you know require lot of work for very short periods of time and then get done. Headhunting I am yet not 100% sure, in the long run, your inhouse HR team needs to build capability to find the type of people you need and essentially you are not letting that capability build. . | Office maintenance, accounts, lawyers etc. These things will not build company competencies if done in-house and are costlier in-house too. . | Some content writing can be outsourced but this is a tricky one as someone from outside your company who can write an article which is good from point of view of your company is hard to find. . | Lead Generation might be outsourced after you have a very good idea of your customer. . | Anything can be outsourced early in startup by the time you are building a in-house team for the purpose, but as founders , its one’s responsibility to get the team in place as fast as possible for any task apart from ones listed in 1–6. The outsourcing companies that drop you regular mails do so because they assume you are a very young startup (or a service company where price cutting is a goal). Points 1–6 are often needed at a very early stage of a startup as well, but can extend too. . | What you should never outsource: . Technology: Technology is your moat, if you outsource that, what competency does your team have. . | Digital Marketing : If you are B2B SaaS, you need to come up with your own digital media marketing strategy to beat or equal asymmetrically large opponents. If you outsource this, how would cookie cutter templates help you equal large and established brands who apply cookie cutter templates too. . | Product Design and Management : Same reason as 1. . | I will add to list as I come up with more ideas. HTH. . My answer to “Is there actually a market for Deep Tech startups in India?” . Originally Answered here: https://qr.ae/pNnZNf . Covering the whole Deep Tech scene in India in one answer would be a bit too much. Couple of chatbots startups are doing OK with Indian banks, do you count chatbots in Deep Tech ? Does acquisition by larger consumer companies count as success (People have made good money there) ? Is the startup building an India specific product or a global product with India as one of its markets? . Some general points I would like to make (running a B2B AI startup ParallelDots . catering to clients in India and abroad): . We don’t have enough datapoints to determine if there is a market: Deep Tech startups need very good technology and a lot of R &amp;D. This increases the number of open ends to 2 in B2C (both R &amp;D and product as opposed to only product in non deep-tech startups) and 3 in B2B (R &amp;D on top of product and integration). &lt;This no way means B2C is easy, its harder in fact&gt;. Indians (both investors and entrepreneurs) often want the easy way out. So a lot of good engineers will want to work with Google’s of the world, entrepreneurs will try to keep lesser open ends in business and Indian investors will invest in much safer ideas. Many Indian startups are direct copies of successful products from US and China. There is much more probability of these working out. My point is there are too many low hanging fruits opposed to trying a Deep tech startup, so not a lot of people get into deep tech. Less people getting into deep tech means less ideas being tried and less visible success giving rise to (somewhat gloomy) questions like “Is there actually a market for Deep Tech startups in India?” . One answer is “we don’t have enough datapoints to determine if there is a market”. This means no ecosystem, no learning material, so learning-the-hard-way for early bird deep tech startups. “Learning the hard way” is a slow multiple-pivot process too. So more open ends added. PS: In no way I blame the Indian psych for this. Life for Indians has sparser rewards than west and they thus are risk averse. Things are getting better and we will see more Deep Tech startups here. Thinking of 11 years back when I joined engineering, there were hardly any startups at all and standard criteria for success was getting a high paying job in US. I think with more success in startup world, we will see successful people (who have had positive reinforcements from previous successes) betting on riskier ideas, some of them getting even more successful. I think the order will be marketplaces -&gt; money transactions -&gt; R &amp;D heavy software -&gt; R &amp;D heavy hardware startups. There is a reason the one-percenters are born in an entrepreneurial society. . | Its hard to discover a deeptech B2C angle (not just in India): There are very few Deep Tech consumer ideas from day 1 in the world. Among FAANG (Apple is a hardware company primarily) only Google was a deeptech consumer software from day 1. Adobe/Microsoft atleast initially were between B2B and B2C. Netflix, Amazon and Facebook have R &amp;D facilities to enhance their product. Same with Uber, Lyft and Airbnb. Successful consumer ideas which can create a network effect are hard to come by and one which uses Deep Tech is even harder (no wonder so few discovered yet). The existing consumer apps evolve into better versions using deep tech creating a railroad like monopoly Development of the Railroad Monopoly . | . DeepTech startups have been acquired by consumer businesses in AI field (in India by Flipkart, Reliance Jio and others) and that is where they will get into usage for vernacular language understanding. I dont know about any AI from day 1 consumer business doing well as of now anywhere in the world. What if Facebook comes up with a blockchain platform in near future ? It will become a monster. Trying to get so many people onboard in a new blockchain startup in India for payments, voting or referendums will be insane, for facebook, its one feature away. . | . In B2B, Indians pay less: The same point again, our economy had almost collapsed 30 years back and we have come upto this point absolutely from nothing. Our enterprises are also becoming bigger, but we are still not like US or China say. Just like consumer startups which are gradually solving more and more high ended problems, enterprises are also only recently waking up to potential of DeepTech. ParallelDots is a B2B business and this is a sector where we see potential in India already. We have been able to sell 30,000 - 200,000 $/year licenses in India for AI software. We have sold similar cost licenses to US companies too, but if we divide the license cost we sell by the market cap of company we sell to, US is ahead. That said, one time customer acquisition cost in India is way lower. India is also more comfortable to sell in(because its home). So both markets have tradeoffs. I will from my current learning say, building a B2B deeptech product only for India probably wont make sense, but building it for world and selling it in India as well seems doable. We are still working out things, but we believe we are closer to make ParallelDots a success. . | . Some other hypothesis we have from our experience in deep tech B2B as of now (please take this as a gain of salt as this is all anecdotal and we are still not exactly the most successful startup out there): * Dont sell to startups * Avoid other B2B companies as first clients, they might either try to acquire IP or might rather create a competitor than try you out. Just saying they shouldn’t be early customers, you can sell established products to them. * Dont build a tool for technology company (esp in AI). Your Deep-Learning-Tools-for-Enterprises Startup Will Fail * Make sure your investor is aligned with you and doesn’t get impatient. Also having a long runway is important. * Try (tech savvy + smart) people as early adopters. They know about technology and will be willing to adopt. Just tech savvy people who are not smart will guide you with wrong/irrelevant use cases, smart but non tech-savvy people might not find your technology relevant. In India, a easy proxy is to search for engineers from IITs etc. at a good level in enterprises. Early adopters are very important. Startup = Growth * Stay away from (non-investing) accelerators, (free/paid but not in equity) advisors and startup schools and focus on product market fit and growth. . | . I am not sure if this answers the question exactly (because as I said earlier, it is a really broad question and there are not enough datapoints to come to conclusions), but it might lead to a good conclusion. . PS: There is of course a huge market for Deep Tech service companies in India. Most of our big software companies are actually service companies and we will have in the near future an “Infosys in AI” from India. I am not talking about them as I dont count them as startups. Its a different type of business with different constraints than what you have here. . My answer to “What is the future of machine learning/deep learning startups?” . Originally answered here: https://qr.ae/TZQf4r . I personally believe startups should be judged as just that : startups. The future of Machine Learning / Deep Learning startups will depend on how successful they are as a startup. . A startup is a business that : . Has Product Market Fit. . | The market of the PMF (point 1) is large enough . | Has a good growth curve MoM or YoY in terms of revenue or usage. . | Can scale the growth with application of more capital. . | There is nothing different a Machine Learning/Deep Learning startup needs to do than the above 4 points. If they are successful at developing a PMF, showing good growth and raising good capital, they will work well. This was true in past, is true now and will be true in the future. . Using Machine Learning/ Deep Learning in a startup increases the risks by a bit (that you have to develop these algorithms) but also functions as a moat in some way. Just building the product itself creates some barrier to entry. . Now come the hype part. Whenever a new technology pops up, be it Deep Learning, Cryptocurrencies, blockchains etc., you will see a lot of money going into the sector. This creates a supply-demand dis-balance and the money can hence take more risk. This is what a bubble is and a lot of startups which are beyond the real metrics (that is the 4 above) get funded in this bubble. We had a bubble like this in Deep Learning startups too. So for example a startup which “makes a free and open source Deep Learning framework in Haskell” might even get funded in this type of an era. “makes a free and open source Deep Learning framework in Haskell” is an example where there is low usage (few data scientists use Haskell, which is a programming language most useful for programming language research) and is still free and open source (no monetization plan). For sure , Deep Learning startups have crossed this hype age and you can see consolidation, as mentioned in the other answer. . My answer to “What are the key factors that influence a startup’s success using an AI technology?” . Originally answered here: https://qr.ae/pNnx9y . I think the following points are marker of a successful AI startup: . Has it got early users ? If it is slightly mature, Has it got a Product Market Fit and has it started generating recurring revenues ? This is pretty similar to what one would expect of any B2B startup. . | Have they been able to setup what we at ParallelDots call “Data Operations Pipeline” ? You need an efficient method to create initial and ongoing supervised training data for AI algorithms ? This is something really important and unless gets sorted, the tech will be lackluster. An AI startup with lackluster tech is meh. Although we might expect Data Scientists to do wonders, they are really nothing without “Data” they can work on. A good metric to evaluate is to check how much annotated training data the startup has. . | Intellectual Property and AI talent: Apart from the network effect in business and data collection, which a business can achieve only after it grows big, the only moat a young startup can create is by their intellectual property and getting good AI talent efficiently. These are things which are slightly hard to judge by non-tech people as a lot of open source and second grade talent can be marketed really well. Good metric to evaluate is publications/ open source contributions and Kaggle scores. . | Some other things to keep in mind are: A. Current day AI generally cannot predict social outcome. (So you cannot tell if someone’s going to be selected for a job interview or guessing someone’s income from their face). It cannot detect weighty subjective opinionated things like fake news (it can recognize some very pattern based instances of fake news though, like heading basically misleading as compared to article). A good rule of thumb is AI can automatically do what you can do within 3 seconds of looking at a datapoint (photo, sentence, excel row etc). How to recognize AI snake oil . | B. Paid developer tooling is generally a bad idea. (because all paid AI tooling is basically developer tooling). Your Deep-Learning-Tools-for-Enterprises Startup Will Fail . C. Google/Amazon/Microsoft will eventually offer AI algorithms which can be used across different companies with no change. For other companies to make dent, they have to work into something that is customized for different countries. For example if you just extract out all faces from images, the behemoths will eventually build an algorithm better than yours. However, training an algorithm to recognize company’s own employees, that is hard to build as a generic service. There are some exceptions to this point like China’s Megvii. D. If you want to enter healthcare AI and it seems your product needs a government approval (like FDA say), it is a lot of work and founders need to have some expertise or hire some. . | . Basically one more point of the above is that AI startups need to have multiple expertise (Tech, AI, Business Development, Operations to collect data and client service). Its a relatively new industry and either you should be able to build a team with the expertise such diverse, and/or founders should be capable of getting out of their comfort zone to build new expertise. . My answer to “How is the AI community shaping up in India ?” . | | . Originally Answered here: https://qr.ae/Teyr1U . I see a lot of blanket answers here like : . Most AI startups are farce. . | They don’t have Prodduct Market Fit. . | They don’t have resources. . | This is because of lack of information. There is no doubt that there is a lot of hype but there are genuine AI first companies in India. If you don’t know about it, please don’t bundle them with the pretentious people you so hate. Hype startups is not a unique phenomenon to India and is very common in Silicon Valley. When a lot of probability of success is dependence upon “impressing” VCs to raise money, you cannot always blame entrepreneurs. Much of what’s being sold as ‘AI’ today is snake oil, says Princeton professor | Computing . . Also a lot of problems in the real world can be solved with simpler technology and you really don’t need AI in everything. Making a startup a success is a hard thing (like really hard). Now you add to it the complexities that come with a AI startup (getting money to buy resources to support the technology and getting a team which can solve the problem statement and startups are expected to grow like crazy while AI research you do is kind of slow), you are basically talking about a way harder to succeed startup. Basically if your odds of succeeding in a startup is 1:100 , succeeding in a AI startup is say 1:500. So the ratio of successful people to pretentious people in AI startup communities is skewed towards the latter (given pretentious people are roughly in the same probability in every sector). I dont blame you too much for generalization, the world does look like that. . First of all, startups who have a different product and are selling a small AI feature will boast about it a lot because they have invested in it to create a differentiator, but they are neither AI startups, nor you should judge AI first startups according to them. . All I would like to say is that there are startups there which have achieved Product Market Fit of a AI first product , have original technology and research and have raised enough money to have a research team and infrastructure to build technology. We will see some of them become success stories in the long run. . Some which I can guess with reasonable confidence which do actual AI work: . AI and Analytics Solutions for Consumer Businesses . Logistics Planning, Automation &amp; Optimization | Supply Chain Optimization Software | Locus . Artificial Intelligence for Radiology . Predible Health . A Novel Breast Cancer Screening Solution . SigTuple . AI powered Video Analytics for Business - Silversparro | Gurugram . Staqu - Perceiving the future . And of course ParallelDots , my own startup. We raised a round of USD 2 Million a few years back and have a rapidly rising Annual Recurring Revenue. We tried out many many products but finally could get a product market fit using our Computer Vision on retail shelves product. . . We do research work ourselves and all our AI technology has been developed in house. . Hope I could show that its not all stupidity here in Indian AI startup scene. . My views on startups disrupting local businesses in answer to “Are technology startups ruining India’s economy ?” . Originally Answered here: https://qr.ae/pNnZGd . Wait.. what ? In no economics book/report will you see such a thing happening. . The general fear from a “Technology Startup” ruining or distorting a traditional business is just Chinese Stories/The frog of the well . type situation. (I hope that is the hypothesis on which this question was asked, I cannot think of another reason why this question will be framed). The world is becoming more centralized, connected and institutionalized. Technology Startups are essentially doing the same thing in India. With the new technology tools available (specifically internet and smartphones), they are making the economy more lean, efficient and competitive and addressing a way larger market making things accessible for consumers using network effect. This might come as a surprise(hence this type of questions) to people only aware of old school businesses who are accustomed to more easier times of smaller markets. India cannot get stuck in the rut of status quo of old days and wait for a rude shock, we have to move with the world, maybe even faster. . To understand more, there are two types of businesses: arbitrage based (an example is taxi hailing services, retail distributor, or a house broker or any such middleman) and Products and Services (a car producing company, a hairdresser, moviemaker etc). A subset of both types of businesses (and specially middleman businesses) exist just because there is an inefficiency in the market. A lot of inefficient Product and Services businesses went out of existence as middlemen slowly connected people to good product/service providers and the bad ones simply vanished. Think of it, a bakery in your area was slowly replaced by cheaper and better product of a bakery which became the most known bakery in the town and then state and country level bakeries slowly formed. So “Middlemen” businesses in fact emerged to solve inefficient “Product and Services” businesses. Most of small businesses in India slowly migrated to Middlemen businesses from product and services businesses. So a television store in your town just does that, buys TV at INR X and sells it at INR (X + Profit). Middleman instead of trying to produce a television. . Now with Internet and Technology, these middlemen are now being optimized one level more. Many layers of inefficient middlemen can now be replaced by a larger company. That is what is happening when Tech startups come up. Its basically the next and modern version of your local singer losing business to Arijeet Singh because ways to transfer good songs over long distance with popularity of audio cassette in 1980s. Ola is replacing your Taxi services, Oyo your typical hotel guy on railway station, Flipkart is replacing your electronic stores and Grofers your grocer shop. They do it at a scale way larger and way more efficient. To win trust, they use cashbacks and discounts instead of their local reputation. . My Answer to “What initiatives should India take to be an AI superpower?” . Original Answer Here: https://qr.ae/TeyruI . Some advantages in India : . Lot of young people. Even if 1% of software engineers in india can be good at AI, we have the largest AI workforce of the world. Similarly, too many entrepreneurs as well. . | Lot of people interested in working in STEM and esp AI. . | Jugaad, art of getting things done with some quirk and meager resources is common. . | Some disadvantages of India: . Youth not attached to country, often aim of many is to settle outside. . | 1 can still be offsetted by our large population, but then, there is too much of a “participation/entitlement culture” . Because we are Indian citizens, we should have easy education (we should have easy access to education, not easy education itself. Most Indian education system is “navigable”, its hard, but we all know there is a way to somehow get through it without putting the work required. Last years’ papers, teacher coachings, getting class notes and other shortcuts. Most students, even the ones who top, will understand what I am saying, they all know there is a way where they could have studied better.). When we get easy education, we want easy jobs. Easy jobs are serfdom, modern serfdom is not as hard as earlier and lot of people want to get stuck there and enjoy life. No “superpower” can come out of serfdom, AI superpower, defence superpower whatever. Discouraging risk taking has to go from our culture. Fear of failing makes our education, jobs, research institutes , universities, companies look for easy hacks out. “Jugaad” (at which Indians are really smart) is a very very good thing if it achieves an objective different from doing-less-work, unfortunately, Indians tend to use Jugaad for this a lot. You all know about the student who scores really well while there is someone else better at the subject, or a famous software engineer who seldom codes and mostly writes Medium blogs. Innovators coming out of our engineering education/jobs/research institutes is exception, not norm, because people figure out shortcuts. You cannot innovate if you are not well educated/avoid hardwork about a topic. Net-Net, easy-way-out thing needs to go from our culture. . | Average Indian is very very ignorant about what is going on in the world. Maybe so is the rest of world too, but hence the rest of world is not a superpower. To be a superpower, India needs to make information reach the last person. There is a set of upcoming skill sets: green energy, AI, blockchain, Genetic Engineering and other things which will change the future. Also called forth industrial revolution, The Fourth Industrial Revolution: what it means and how to respond . | , we need to grow skills towards these new industries if we need to be a superpower. Indian students who will enter the labour market soon are wrongly advised and often end up studying for subjects which have literally very few opportunities in India. As a result , we have millions and millions of students who study for years in courses which they will not need. Think about how many millions of years we have wasted. So for handful of Civil Engineering jobs, where in India, one can just get in by a Polytechnic education ( Continuing education - Wikipedia), we have students in almost all Engineering Colleges doing Civil Engineering majors. Why so ? A lot of them join jobs unrelated to their degree. We essentially convert degree workforce into secondary educated workforce. . So yes looking at points above, we need the following: . Solve the information asymmetry. Tell people what is the next big thing. Eventually people will understand, but we need to convert all the millions of years (mentioned earlier) we are wasting into good resources. This efficiency in economy will help us getting ahead fast. Government actually gets many surveys done, but it needs to let the information reach the masses the languages they can understand. Maybe something like a “Mann Ki Baat” for education and industry or Modi dedicating a few of these episodes to such topics ? (I will actually try suggesting this on their online suggestions portal). Indians pay for Education. The recent wave of eductech startups might also solve this really well, but a more sober and serious voice than a young entrepreneur needs to convince the people that doing stupid majors is not worth it. . | Make failing while trying to learn and do acceptable. We have designed our incentives wrong way. Most of our people will find a person completing a PHD in 5 years with better publications worse than someone completing their PHD in 4 years with worse publications. We can maybe have research/entreprenurship courses in all degrees where we give marks for amount of hardwork done and not results. It sounds easy, but Indians are master at avoiding hardwork as I told earlier, so needs to be done cleverly. In fact in a world where research is becoming very important (most industrial revolution 4 technologies need a graduate + level education) , we don’t have enough top tier people doing research and its generally considered a career for those who want to do a “teaching” (not academic) job. This is a cultural thing and needs a collective resolve to move ahead. . | Government needs to stop giving useless scholarships in irrelevant subjects and direct this money into new sectors. I heard recently that there is scholarship for studying (even research in these languages might not help the nation, but this scholarship is for doing a Bachelor degree, you need to pay like 3 cents a month as residential fees) Pashto and Persian in JNU. I don’t think that there is anyway this will help the country. We need to divert the money into STEM research, specifically AI. Good resources flowing into AI research will definitely change the picture a lot. Think of economically weak students studying Computer Engineering on similar scholarships. . | Force people out of their comfort zone: This is not easy, but unless people are made to get out of their comfort zones, we wont get the efficiency required to become a post Industrial Revolution 4 superpower. Professors who are doing ineffective research need to be transitioned into a role where they can solve useful problems, companies need to attack more open-ended business problems to solve with AI and government needs to redirect investment from useless research and departments and PSUs to things that will yield good results in future. We need to make sure people are ready to get reeducated and reassigned and we need to then quickly change face of our economy. This involves lot of uncertainties and people will need to adapt. As expected, it will be a hard pill to swallow, but better adapt before someone forces to adapt. Like point 2 this needs a collective resolve. . | So , sum total, we need to develop a collective resolve to change the current situation. getting ahead in any field (including AI) needs resolve to change. Comfortable life if not something that will make you move ahead at a pace you can defeat others. . My Answer to “Where does India stand in AI, 5G, quantum computing, biotech, and clean energy?” . Originally Answered Here: https://qr.ae/pNncYq . India is one of the leaders in Clean Energy : . . Video URL Here: https://youtu.be/fyqDC_AKVgE . India is also a quite advanced country in BioTech, esp. Agriculture related : . http://www.crri.nic.in/crri_sucstory.htm#Highprotine_rice . CRRI-Success Stories . India’s first transgenic food crop edges toward approval . Achievements - ICAR- IIWBR . India is the largest producer of vaccines in the world and its technology saves millions of lives : . Trusting the science . . India has its own Artificial Intelligence startup scene as you might have read above . And with certain steps like ones mentioned earlier, we can ensure that India might even become an AI superpower. . With government trying to bringing in some large scale projects, you can expect the AI capabilities to grow: Muktabh Mayank’s answer to What do you think about India building the world’s largest face recognition system? . As usual, being in top 10 is easy, being the best is really really hard in any of the fields I mentioned above. But India is giving a good fight I would say. . Quantum Computing is still a very early stage technology and frankly I doubt a lot of “real” work is happening outside US, which is the innovation capital of the world. . 5G is a lost cause, we have no companies that work in 5G technologies and all our telecom companies will be doing is paying huge sums of money to Chinese companies like Huawei to install these new cellphone networks. The technology will roll out soon in India, but it won’t be Indian technology as such. .",
            "url": "https://muktabh.xyz/2020/04/14/Views-on-Indian-Startups.html",
            "relUrl": "/2020/04/14/Views-on-Indian-Startups.html",
            "date": " • Apr 14, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Viewes On Fresher Data Science Jobs",
            "content": "Machine Learning Jobs for beginners/freshers : My Perspective from various Quora Answers . I will collect some of my answers here regarding fresher Machine Learrning jobs in India as I have some experience in this domain and hire in this domain quite often . Q. What should I do to get a job in Machine Learning in India ? . It’s a simple rule, work on an interesting project, get some results and put on display (Google, kaggle etc). Most employers can gauge your interest when they look at your profile. An entry level Machine Learning Engineer who can explain the Maths behind the algorithms they apply in some non-trivial problem is good enough for a lot of companies, they are not expecting seasoned veterans. . The following types of projects look very impressive: . Taking a research/kaggle competition and working on its dataset. The code to handle such problems is a good proof of ones capability. The other good way is contributions to open source ML. The more you know what works behind your solution, the better. . | Taking a paper (or taking a set of papers by a research group) and trying to code the algorithm/replicate the results is even better than 1 (at least for us at ParallelDots). . | An academic/industrial publication is even better. . | The following is what is not enough: . Forking code for Bicycle challenge or other such competitions (the Titanic one as well) and running it and submitting that as previous work. They are too many tutorials for them and people won’t take you seriously. . | Completing Andrew Ng course. . | Unless you are applying in a very big enterprise, I will say avoid certification and try working on personal projects. That is way more impressive. . | Again, Please don’t just fork code on Github and expect employers to believe you have worked. Its easy to see how much you have worked. :( . | HTH. . Answer is here: https://www.quora.com/What-should-I-do-next-for-getting-a-job-in-Data-Science-and-Machine-Learning-in-India/answer/Muktabh-Mayank?srid=qie . Q. Is it not possible for a fresher to work as a Machine Learning Engineer ? . It is not “not possible” for a fresher to join as machine learning engineer if he she is very good at it. Wrong conclusion. . I have seen freshers taking role of machine learning engineer at enterprises and even my startup. The problem is “he she is very good at it” part . Freshers often (not always, I know freshers with CVs as good as a professional ML engineer) over estimate their CVs as they don’t know about how real world works , they have very high expectations due to that and real world is unable to meet that. . Answer is here: https://www.quora.com/Why-is-it-almost-impossible-for-a-fresher-to-join-as-a-ML-engineer-even-though-he-is-very-good-at-it/answer/Muktabh-Mayank?srid=qie . Q. What is the learning path after going through basic Machine Leaning material ? . Does one do projects, go for a summer training in Hadoop in Delhi, read books ? . (Please see link to blog posts below to find all these books) . IMHO, projects are the best way to learn (as you said you want to become a factory data scientist and are not in a mood to pursue a higher degree ). Taking different datasets for different types of problems and trying to come up with a data processing pipeline and then applying Machine Learning algorithms on top of it helped to clear many concepts for me. Its way more fun than all theory. Look at UCI or Kaggle datasets to apply your skills. . 1. From where should I do summer training in big data hadoop(Delhi)? (or in any other specific technology) . Dont. Hadoop is just a framework to write programs. If from starting years of your career, you start concentrating on technologies (hadoop / mysql / postgre / java / python / scala and stuff like that), you will end up becoming a &lt;specific technology&gt; professional (say hadoop professional). Technology trends come and go, unless the fundamentals (which here is distributed computing) behind them is clear, one would never be able to adapt to the changing market . As long as you know programming basics well, stuff like Hadoop would be easy to pick up when your job requires it. You can try triggering a mapreduce job on your local system with help of an online tutorial, that is a different thing, but taking a full on course on hadoop is neither required nor recommended. . There are some other points I would like to specify as well: . a) Hadoop is for handling very large amount of data (Terabyte+), which most places do not have. Unlike what the internet hype (and plethora of hadoop training institutes in India want you to believe), most companies still have small data which can fit easily on a postgres cluster if not one server. Data Analysis skill is required almost everywhere, Hadoop at best in few 100 offices in India. . b) Apart from HDFS, most parts of hadoop ecosystem are already being replaced/renovated by the innovation leader companies. Google (the inventor) phased out mapreduce The Elephant was a Trojan Horse: On the Death of Map-Reduce at Google, projects like mahout already seem to be moving away from hadoop and a lot of companies seem to be moving towards Apache Spark™ - Lightning-Fast Cluster Computing . Now by the time you become professional, spark might be the talk of the town, in 10 more years even it might be removed. . I would rather advice you to read books like mmds, foundations of data science, ISLR, Deep Learning etc. All of them are freely available on internet. Save your money and time (reading them now than you would read them after you graduate). . Edit : Adding the link to books (will rather link the blog post at ParallelDots we made collecting links to all these books, most of them freely available) . Free Machine Learning Books . Free Data Science Books . Free Deep Learning Resources . Must Follow Blogs . Answer is Here: https://www.quora.com/What-should-be-the-learning-path-after-going-through-basic-machine-learning-material/answer/Muktabh-Mayank?srid=qie . Q. Do companies hire data scientists with zero internship experience? . Yes. Doing an internship is not necessary to work in Data Science. . But most companies won’t hire Data Scientists with no experience of solving real world problems. . I would say anything out the following gives you equal (or more) weightage than internship at a tech startup. . A bronze medal or better at Kaggle, . | A research project under an academic that resulted in a publication at a decent venue, . | An internship doing a proper AI project (which is to be deployed within the company), (whose alternatives we are discussing), . | Contribution to an open source project, . | Some other way in which you have worked in a real world setting optimizing for different constraints. . | The bigger companies working in Data Science, maybe like Fractal and Manthan, might be hiring absolute freshers too, but most companies in this space are small startups who cannot take risk if hiring absolute freshers and training them. . Original Answer Link: https://qr.ae/pNnch5 . Q. Is it true that maths or statistics isn’t required at all in data science while programming skills are required? My friend told me the same thing. He said that’s why a majority of data scientists are from BTech backgrounds, not from maths or stats. . Any respectable Engineering program (BTech) has a sizable number of Maths and Statistics courses. At BITS Pilani, I had coursework in Vector Calculus, Statistics, Linear Algebra, Differential Equations, Optimization and Operations Research (each one was a separate 1 semester long course) which every Engineering student had to take. On top of this there were Computer Science specific subjects (Data Mining, Machine Learning) which taught the Maths and Programming part both to everyone. The theory taught in these many courses is frankly enough to read most Data Science papers and understand concepts (You might need to read a couple of tutorials here and there). . So the hypothesis that Engineering students aren’t aware of Maths and Stats is a wrong one. . Now about Data Scientists not needing Maths skill, data scientist as a job description is very broad just like software development. . You can say that Software Engineer doesn’t need to know about Databases, and that will be true for many people: Software Engineers who write Operating Systems, Software Engineers who develop frontend applications, Software Engineers who write compilers and below par Software Engineers who work on web application backends. . There are similarly many job descriptions for Data Scientists. Some of them actually don’t require too much Maths and just programming, but most of them do require some basics of the above mentioned mathematical areas. . Original Answer Here: https://qr.ae/pNnctE . Q. My answer to “What are the mistakes people make when they start Machine Learning?” . Originally Answered here: https://qr.ae/TiNJou . Some mistakes according to me: . Focusing too much on math in the initial stages. To train your first Neural networks, you don’t need to know in detail how backprop works (backprop derivatives of all ops for example), or you don’t need to understand the support vector derivation to train SVMs. Dont start reading complicated mathematical resources in the beginning, it makes learning very slow. Touch on these topics when you are somewhat experienced writing code and training algorithms. . | Focusing too little on Math is similarly bad too. Not knowing what different parameters to a Conv layer in Keras signify is also sub optimal. A basic book on Machine Learning with theory is best starting point. . | Practising less. This is what differentiates between good and excellent practitioners. Most excellent practitioners can think of 100s of ideas around a dataset and can iterate quickly on them. That is how accuracy on a dataset will go up. Other practitioners will waste time in thinking about what would be the perfect method and code their “one best” method in hours, which will mostly not work in the end. You cannot think in advance what should be the method for best accuracy, EDA and trail-and-error is the key. Remember during practicing “Getting average accuracy on multiple datasets &lt;&lt; multiple round of iteration to get good accuracy on one dataset”. . | Not focusing on basics numpy and pandas. As I said earlier, you need to iterate over many ideas quickly rather than thinking of “one true idea” that will work. Its grit boring work. To make this quicker, good command on Numpy and Pandas help. Lesser number of Google searhes == more code. Tensorflow/PyTorch have been purposefully written close to Numpy to make sure that Numpy users can iterate quickly. . | Q. What are some signs to recognize inexperienced Machine learning engineers ? . Original Answer Here: https://qr.ae/pNncvm . In my view most inexperienced Machine Learning people (including me say 6–7 years back) focus more on algorithm than data. . Newbies want to try out all the 250 (dummy number) algorithms on the dataset they have got without EDA on the data itself. . Changing the algorithm will generally give what 2–3% (again dummy number for giving an idea about magnitude) gains in accuracy, while, arranging/ balancing/ feature engineering/ augmenting the data can give manifold accuracy gains. . Machine Learning is not yet a cool art where you summon a Charlizard and then it will be burn the competitor to the ground. It requires grit, getting dirty with the data and understanding what is the algorithm learning through many boring iterations. . Q. I just hired an unqualified machine learning engineer, he know only some basic Tensorflow and have no idea about the maths and build more complex neural networks, should I fire him immediately or give him 2 months to improve? . Originally Answered Here: https://qr.ae/pNncrn . Why did you hire an “unqualified” person ? Don’t you have a job description and interview process ? If there is such a huge gap between the hiring and requirement, I think its a problem with the company leadership and process. You should understand who you want to hire for what exact profile before you even put the JD out. . What you should do next is dependent on what is expected of the employee in the long term. . Do you expect him to do something Math(y) ? I don’t think they will be able to learn in 2 months. OTOH, 99.9% of the companies won’t need people who can write “new and complex” neural networks. Its mostly about transforming the data well, using clever training methods and loss functions etc. That said, even to gain enough experience for this, they will need more than 2 months. . The general observation I have is that a lot of companies don’t have clear specs and requirements and they expect their Data Scientists to weave magic. Then they won’t hire senior people who can tell what is possible and what is not and put the entire pressure of expectations on cheap “fresher” employees, who generally have no real world experience (and many times will overestimate their capabilities, thus signing into something they cannot accomplish). This type of org structure is a house of cards. Hope this is not the case with your organization. . If the work is running different open source models and experiments, 2 months is a decent time to learn and apply. If your expectation is in a domain , which is well worked and researched in, 2 months should be a good time for a less experienced person to catch up. If the expected work is this much, the hiring strategy is also not wrong and this is the general capability of talent available in the market. Groom them a bit for 2 months and everything should work out. If the expectation is any more open ended, you have made a wrong hiring decision. . Q. Will the talent shortage in AI end soon? . Originally Answered Here: https://qr.ae/TSkAzo . There is no shortage of AI talent as of 2019 end. Too many people in India know basics about AI and can be trained to work. I am not sure if there is a way to see people applying for AI positions but if there was a way, you could clearly see that way many people apply for all AI/Data Science job (at least here in India). There was a time when just knowing some basics got you a job but no more now. . The problem has now shifted to retaining top talent as too many people in the world are applying AI and working abroad is a big deal for most Indians. So the situation is a lot more like Software Development profiles now for most AI profiles too. . There is a huge pool of talent and there is arms race for retaining top talent. . Q. Will data science and machine learning get automated leading to lesser opportunities for data scientists by 2025 ? . This blog post is also an answer by me on Quora here. . Yes. (2025 is not the date I think its going to happen, but its inevitable and will happen in near future). They will be automated to a good extent. So will be Software Developers, designers, manual workers, teachers, linguists, musicians, game developers etc,etc. There are already rudimentary projects like Turning Design Mockups Into Code With Deep Learning which can turn a design mockup into HTML/CSS code, carpedm20/ENAS-pytorch which can design neural networks without a Data Scientist, Why AutoML Is Set To Become The Future Of Artificial Intelligence , system which can generate new characters for games, Microsoft AI can translate Chinese to English just as accurately as humans , Baidu’s Deep Voice can clone speech with less than four seconds of training | Computing and multiple such projects. . . Video Link : https://youtu.be/XOxxPcy5Gr4 . AI will impact every job profile which exists as of now, Data Scientists no exception, automating some or a lot of work people spend their time on. For a lot of time these systems will become a &lt;Man + Machine&gt; AI systems rather than just a Human working before stuff is totally automated. So its not like everyone becomes redundant day 1, but they will eventually. . Full Automation of any field is going to take way longer than 2025 IMHO. That said, yes a lot less people will be needed for the same task as of today. Then what will people do you ask ? newer more complex tasks. . Automation is not a new phenomenon. Think about the railway breaks a long time back: . . Video Link Here: https://youtu.be/EEUkmP2nyxo . So much work was once needed to just stop the train. A lot lesser work is needed today to run/stop the train and not just that, slowly trains are moving towards full automation, but right now they are in a &lt;man + machine&gt; stage. A lot of jobs will stay in this phase for sometime before full automation kicks in. But unlike railways, which take generations to move from one stage of automation to another, AI is causing changes at a very high rate. . What is the effect on a general Data Scientist (or any white/blue collared worker for that matter): . Adapt to AI. Automation has started, but AI aided jobs will stay for a few more years than non-AI jobs. So while no plain X jobs by 2025, X + AI jobs might be around till 2030. . | Things wont be like earlier generations where one skill learnt gets you a job for entire life. One needs to be open to learning new skills and get started in the middle of life. . | Average level of education needed will be high. Think of it, 50 years back “High School” was all the education needed for most jobs. Now its somewhere between high school and graduation. Masters and Research might look like the next frontier, but these degrees are too slow and broad. Coursera like courses will become more important in catching new skillsets. You might already see people doing that a lot. . | With more uncertainty in jobs, millenials probably will want to be a less “spend-y” and more frugal. You can see things happening already 6 reasons why more millennials aren’t buying homes and will actually increase. AI is just a trend in a longer cycle of Automation and millenials are at a point in history where education+society was according to old norms but automation has reached a point where jobs have become uncertain. Younger people will be smarter. . Q. Why are Kaggle Grandmasters in a great demand? . | | Because they work really really hard on Applied Machine Learning (that’s what kaggle is) and thus have become really good at their job. If there is a hard Machine Learning problem with Billion dollars behind it, with a high probability, Kaggle grandmasters will be able to solve it better than an average joe. . Working consistently on something for years makes one a master of the art. Outliers (book) - Wikipedia . . People really good at their job (say in top 10%) are really sought after in any field, not just Machine Learning. They drive the innovation, solve open ended problems and hence they get the rewards. . . Q. How do I become a data scientist in 2020 in India by self-teaching? . I originally answered the question on Quora here: https://qr.ae/TmYc20 . I don’t think the path to being Data Scientist in India is different from being a Data Scientist abroad. It is in fact 99% same if you live in a place with good internet connectivity and understand English. . You have to clarify to yourself the following: . 1. As a self-learner, determine if you like learning from books or like learning in virtual classrooms. . 2. Either way, you will have to dedicate around 10000 hours of hard work to learning and practical exercises. It looks simple, but most people lose out here. They do not put enough effort. . 3. Point 2 above requires self drive. It is not easy. A proxy to that is buying online courses / books. The money you put into them makes you (and probably your parents who drive most people towards learning stuff) have skin-in-the-game and you wont want to lose out. If you arent that wealthy, you will have to push yourself. . 4. You have to invest in a good computer. (somewhat 60000 INR cost). . 5. You need to have good internet. . | That is all. There are enough resources available for free to learn and make yourself a good data scientist. . 1. Learn Python programming. This is first and foremost. There are many free books and online courses to learn Python (sometimes Python for Data Science specifically) if you aren’t enrolling in a course. When you are doing a course or reading a book, don’t just read it, force yourself into using python after you are done learning. If book exercises look boring to you, join a startup near you as a free intern and do some coding for them. Forcing yourself to write 1000 lines of code (made up number) is very important. . 2. Make yourself comfortable with Python ecosystem : Numpy, Scikit_learn, Keras, PyTorch, Pandas. There are courses and free books available to do these. Look for their ratings on goodreads (for books) and course stars. Best is to just do the famous courses Applied Data Science with Python | Coursera , http://deeplearning.ai and Machine Learning | Coursera . If you are looking for free books, check out some lists I curated on ParallelDots blog: https://blog.paralleldots.com/data-science/50-must-read-free-books-for-every-data-science-enthusiast/ , https://blog.paralleldots.com/data-science/24-best-and-free-books-to-understand-machine-learning/ , https://blog.paralleldots.com/data-science/deep-learning/free-resources-deep-learning/ , https://blog.paralleldots.com/data-science/nlp/free-natural-language-processing-resources/ . Force yourself to write more and more code. Do problem sets from courses, exercises from books, work for free in a startup, enter analyticsvidhya competitions or whatever suits you. Unless you practice after you learn, its not going to work. . 3. This much will make you employable by many companies. If you still are trying to push to learn more, you will have to start reading research literature. This is not entirely necessary, but if you still want to, you should get yourself associated with some decent university group (or a research startup), where novel problem statements are being solved. This step is really hard without talking to peers, but if you are really self driven, Twitter is a good place to follow people and handles to learn about research while being outside the research world. Becoming an Independent Researcher and getting published in ICLR with spotlight . |",
            "url": "https://muktabh.xyz/2020/03/20/Viewes-on-Fresher-Data-Science-Jobs.html",
            "relUrl": "/2020/03/20/Viewes-on-Fresher-Data-Science-Jobs.html",
            "date": " • Mar 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Some Coronavirus Facts",
            "content": "What we know about CoronaVirus ? What to do and what not to ? . I decided to write this as new cases of CoronaVirus have come up in India in early March 2020. I thus want to make as much information publicly (and easily) available. . Surprisingly, we don’t know a lot about the virus ! For Science, answers to a lot of questions are “We don’t know”. With the bombardment of facts and opinions coming to you through social media, you should understand what is True and what is a guess. . What is CoronaVirus and where does it come from ? . Coronavirus is a very common species of virus. It is found in different animals and generally doesn’t effect humans. . However the nCov (novel Coronavirus) is a particular type of coronavirus which causes COVID19 disease. The disease that is wreaking a havoc in China, South Korea, Italy ands Iran and many people have already died. COVID19 can cause Flu-like symptoms and can grow to severe pneumonia or organ failure causing deaths. . https://www.statnews.com/2020/02/14/disease-modelers-see-future-of-covid-19/ . . The trouble with COVID19 is that while it is very contagious like the common flu, it is really deadly. (A preprint from a Chinese study centre says it kills upto 4% of the people it infects). A lot more people will experience severe symptoms when they contract the disease. . Cite: https://www.medrxiv.org/content/10.1101/2020.02.10.20021675v2 . There are other studies that show morality rate to be between 1%-2% as well. . . The coronavirus which causes COVID19 was not around until a few days back. It is a mixture of two different Coronavirus strains from two different animals. Bats have a unique type of immune system (ie, it is always working at full capacity to defect against viruses), so the virus which have evolved to attack bats are really fast to spread so that they can overwhelm the immune system. When such viruses evolve to attack humans, they become very deadly as unlike bats, human immune system triggers after it is sure of an infection. This viruses thus find it relatively easier to overwhelm human immune system than in bats. . Bats have been source of many different viruses that have effected humans in recent years. SARS (last decade in China), Ebola (few years back in Liberia and surrounding countries in Africa), Nipah virus (few years back in India) all came from bats. With humans intruding into natural habitats (forests) of bats, the frequency of encounters is bound to go up. . https://phys.org/news/2020-02-coronavirus-outbreak-viruses-deadly.html . . What makes the matter even worst is the consumption of wild animals as meat in some areas of the world. This leads to unregulated sales of wild animal meat in open markets. In Africa’s Ebola outbreak, bushmeat consumption is what causes the Ebola virus to evolve into the deadly thing it became. Bushmeat Importation Policies | CDC . . In China, wet markets , or markets where exotic animals and seafood are kept together and killed for human consumption are supposed to be the cause of Coronavirus outbreak. The bat coronavirus is not able to infect humans directly. However, there was a transfer of the virus from bats to most probably pangolins when they were kept together or their body fluids got mixed before they became capable enough to attack humans. . https://medicalxpress.com/news/2020-02-pangolin-potential-link-coronavirus.html . https://phys.org/news/2020-02-illegally-trafficked-pangolins-link-coronavirus.html . . However, it seems that the Pangolin discovery was an incorrect one. All we know is Bat Coronavirus merged with another strain and became nCov we know today. So we don’t yet fully know how the virus originated. . https://www.nature.com/articles/d41586-020-00548-w . . SARS, another Coronavirus outbreak in the previous decade was caused due to human consumption of civets. . . Remember while the nCov originated in animals, it has the capability to spread from person to person. So don’t be under the assumption if you avoid animals you are not at risk. nCov somewhat spreads like common cold and flu. . Now, that we know where did the virus come from, we can now understand how it spreads. Coronavirus is slightly heavy as compared to the common cold virus, rhinovirus. So the probability of it being aerosolized as an infected person sneezes or coughs are slightly lower. And even if that happens, the virus will be able to travel less distance in air. . So, stand away from people showing symptoms like sneezing and coughing. . However, people can infect doorknobs, mobile screens, washroom faucets when they touch these objects. The virus can then be picked by other people when they use the objects upto a week after an infected person touches them. . If the virus reaches a new person’s hands, it will not get into by skin, but when they touch eyes, ears, nose or mouth with these hands without washing. If an infected person sneezes or coughs very close to an uninfected person’s face, water droplets can enter their eyes or mouth directly. . So, wash your hands very very often with a disinfectant like Dettol etc. Also when in a supposedly infected area, cover your nose, mouth and eyes with a mask and glasses. When used, dispose these object cleverly and wash hands afterwards. . . People have also started inventing clever touch-less buttons etc. to avoid getting in touch of infected surfaces. . My friend CTT came up with a very interesting design for proximity sensing, no-contact elevator buttons- that still provide the satisfying visual movement of being pressed. pic.twitter.com/fpUEs4mLQ8 . — Naomi Wu 机械妖姬 (@RealSexyCyborg) February 12, 2020 . The following section about growth was written in early February and in China the growth rate seems to have slowed down since then, however, outside China you can see a similar growth rate in Korea, Iran etc. : . Remember, prevention is the only thing possible right now. There is no known cure as of 15th Feb. Many medicines are being given a trial and we might have one soon, in a few months, years or maybe never. . If you look at NN Taleb’s predictions, the virus will spread like wildfire. Surprisingly, the virus has been following an exponential curve for sometime as expected. . . . In general, some tips : . Avoid crowds and travel unless absolutely necessary. This reduces the probability of you getting in contact with the virus. . | Keep some long shelf life products like rice, grams etc ready at home. . | Try having a Water purification system that works without electricity too. You dont want to increase risk of other water borne infections. . | Stock medicines for other conditions like fever etc and for hypertension, high BP, diabetes if someone has the conditions in your family. . | Avoid shaking hands and try staying away from other crowds and unnecessary travelling. Going out in crowds increases your risk factor for contracting coronavirus. . | . Remember, this is way more serious than common flu unlike what many MSM outlets are saying. . If the answer has made you panic, here is some Simpsons (predicts future) humor: . . Also , here is an Indian Newspaper reporting the humor as if it is real news: . ‘The Simpsons’ predicts the future, again: Episode cited as a prophecy of the coronavirus . Now for people who like reading specific answers, I will write answers for various FAQs: . Q1. Are vegetarians immune to COVID19 ? . A1. COVID19 originated in wet markets selling meat, but it now has human to human transfer capacity like Common Cold and Flu. Staying away from animals reduces risk of coronavirus contraction, but there is no guarantee that no animal contact makes you safe. So no, vegetarians are not immune to COVID 19. . Q2. Are masks helpful or not ? . A2. CoronaVirus is a heavier virus when compared to say common cold. So it cannot stay suspended in air for very long. This means that if you are standing away from an infected person (2 Meters +), there is a very low probability of virus contraction from air. So that means you do not need masks as long as you are in spaces where people aren’t too closeby to you. Only in places where infection is widespread (like hospitals) and in cases where you have to get too close to people infected with CoronaVirus, you should use a mask. Also please note using a mask is almost useless without using protective eye wear. When you use a mask, you should dispose it off well and wash your hands after removing the mask. Please note its better to avoid infected places and mass gatherings than using masks. Not only masks are not 100% effective, you also choke the supply for health workers who require these to take care of the sick. Please read the directions if you choose to wear masks : https://www.who.int/emergencies/diseases/novel-coronavirus-2019/advice-for-public/when-and-how-to-use-masks . Also remember to not buy and stockpile masks, this creates shortage and health workers need them much more than you do. . Q3. As a normal person, what is the most effective way to avoid infection ? . A3. Minimize going into public places. That is the most effective method and reduces the probability of you catching the infection by a lot. Keep washing your hands frequently using alcohol sanitizers or soap. It has been scientifically proven that it works quite well. Avoid touching your eyes, mouth or nose unnecessarily. If you feel a strong need to do so, clean your hands before doing so. The disease seems to be spreading through contaminated surfaces like door knobs, lift buttons, phone screens etc. Practice hand hygiene after touching any such possible surface. https://twitter.com/layallivs/status/1234849244709883905?s=08 . . Q4. Isn’t the COVID19 just another Flu ? . A4. No, its not. COVID19 has a way higher fatality rate (best estimates around 1- 2%) and need for hospitalization rate than normal Flu from what we know. There is no comparison. For elderly people, the mortality rate can be as high as 1 in 3. You should make sure you dont act as a carrier for virus infecting elderly people. Luckily, for people younger than 20 years, COVID mortality rate is really less. . Q5. It doesn’t seem to be as deadly as say Ebola. Why so much worry ? . A5. Because COVID19 follows textbook definition of Viral. If it starts spreading, it spreads at a rapid rate and 2% of a large number can be a very high number. For example, if allowed to spread unconstrained, it can spread to population as large as 40%-70% of the entire world. That’s over 3 Billion people. 2% of 3 Billion is 60 Million lives! That would be a terrible terrible loss. . Q6. Does the virus die in hot/humid temperatures ? . A6. Maybe. We don’t know for sure. It might be that the virus becomes inactive in hot and humid weather. That conclusion comes from that it has spread less in tropics than temperate/cold climate. But this might just be a co-incidence. As of 4th March 2020, you cannot be sure that the virus will not spread in your vicinity because of it being hot and humid. . Q7. Why is India still getting an increased number of coronavirus cases per day if they are locked down for a while? . That is quite simple: . Most of the people as of now (24th March) tested positive for CoronaVirus are Indian and Foreign citizens who returned from abroad (the remaining ones are people who came in contact with this). While India stopped visas a long time back, its own citizens from abroad were thronging to our airports (its just two days back all international traffic was stopped). Our citizens continued entering just upto two days back. About 26000 people entered Mumbai from Dubai, we have no way to control infection amongst people who are arriving pre-infected here. Coronavirus: Worst-hit Maharashtra set to welcome 26,000 Gulf returnees . | . The number of Corona cases you see on Television is actually a snapshot of a few days to a few weeks back. Reason its is seen COVID19 doesn’t show symptoms immediately. It takes a few days to 2 weeks for symptoms to emerge and then people visit hospitals at different stages after the symptoms appear. They are spreading the virus all along. The lockdowns were imposed only a few days back. . | The first few days of lockdown were voluntary and while majority of people followed them, there were a few people who did not take it seriously. While the rate would have definitly fallen (we would see good numbers in a few days to weeks), but now that absolute lockdowns are being ensured, it should get even better beyond that. . Q8. If a person has had the coronavirus, are they more or less likely to contract it a second time? . | | Unfortunately, we don’t know that yet. We have opinions but no definite conclusion. . CoronaVirus (not the recent one causing COVID19, but other more common types), along with RhinoVirus cause common cold and it seems the body doesn’t develop an immunity against that disease. You keep getting the cold every year, dont you ? . Why Don’t We Ever Develop Immunity Against the Common Cold? . On the other hand, there are arguments like a certain portion of human population are innately immune against the COVID19 causing virus. If a few people can be immune, so can be all people with immunization/exposure. . Coronavirus spread is slowing - Says Israeli Nobel Laureate . Q9. As there is no vaccine for coronavirus, how are people being cured of it? . Vaccines don’t cure you from viruses. Your immune system cures you by destroying cells infected by viruses. The aim of a vaccine is to somehow make sure that your immune system is already ready with a response for a virus we know humans aren’t innately immune to. This is done by delivering a harmless entity like weakened virus or a clue to recognize the virus (protein etc) into the body so that immune system learns to recognize and kill beforehand. . In case of a novel virus (something never seen before), the body’s immune system has no clue about the virus and has to come up with a strategy to kill the virus while being infected. Novel-Coronavirus (SARS2 which causes COVID19) is a novel virus. Unlike a vaccine , where a body learns to fight the virus for free, here its a question of whether body can come up with a strategy to kill the virus before the virus does serious damage. . For a lot of people (over 95%), their bodies are able to come up with methods to beat the Novel-CoronaVirus when they get infected. (It is not known whether the body develops long term immunity post getting better though) . For the others, the results might be really bad :( . Specially people who have weakened immune systems (people take drugs to weaken immune response in various diseases), diabetes, high BP or weak lungs/organs due to smoking. . So for people whose immunity cannot fight off COVID19 (or even whose immunity can fight it off), another way to stop the virus is antiviral drugs. These drugs (generally) stop production of various viral proteins reducing/stopping the growth of virus, thus reducing the work of immune system to kill the virus. There are a few antiviral treatments that might be working for COVID19. We still have very primary data about it, but people are already using these drugs as last resort: . Hydroxy Choloroquin + Azithromycin seems to work in a trial in France. There have been other studies about Chloroquin derivatives in COVID19 outbreak as well as before it (during SARS outbreak in 2002). Hydroxychloroquine and azithromycin as a treatment of COVID-19: results of an open-label non-randomized clinical trial . | Meplazumab has been tried in China and seems to work well : Meplazumab treats COVID-19 pneumonia: an open-labelled, concurrent controlled add-on clinical trial . | Japanese drug Favipiravir has been found to be successful in a trial of 340 patients as claimed by China. Japanese flu drug ‘clearly effective’ in treating coronavirus, officials say . | Remdesivir might be another drug that could be proven in future to cure off the virus: FDA Grants Experimental Coronavirus Drug Benefits For Rare Disease Treatments . ## . Q10. Aside from a Pune-based diagnostic company, myLab has developed the first made in India test kit for coronavirus in a record time of 6 weeks. How will this help us to control corona? . | | The more testing kits we have, more people we can test and isolate. Not just this, myLab kits also provide results fast. This helps stop spread by identifying all infected quickly by testing more suspects. . In a hypothetical condition, if the entire 1.3 Billion people are tested and people who have the virus are isolated, and everyone entering country is given a coronavirus test, the others can go about doing day-to-day work as if nothing has happened as there will be no danger of infection. Until this is not achieved heavy quarantine will be needed (the more you can test and isolate, the lesser quarantine is needed like South Korea). Importing 1.3 Billion kits will probably cost a huge chunk of India’s GDP ! If we could build it in house cheaply, it would be pretty good, not 1 Billion, then say 100 Million. . We have to make a model between China’s model and South Korea’s model. (that’s what government is doing) .",
            "url": "https://muktabh.xyz/2020/02/27/Some-Coronavirus-Facts.html",
            "relUrl": "/2020/02/27/Some-Coronavirus-Facts.html",
            "date": " • Feb 27, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Muktabh Mayank Srivastava. I am a Data Scientist and an Entrepreneur. I work on Product Architecture and Machine Learning Research at my startup ParallelDots . I am very active on Quora and Twitter and you can get in touch with me there. You can find my research at my Google Scholar page. . The following types of posts exist here : . List of my chosen (long) answers from Quora from many topics. . | Some highlights from my interest in Computer Science and Machine Learning. . | Some lessons learnt the hard way working in my startup. . | Musings on The World, Science, History and India. . | . ![](https://muktabh.xyz/images/me.jpg &quot;Muktabh&#39;s Pic&quot;) . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://muktabh.xyz/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://muktabh.xyz/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}